{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj_bG0X2PtRT",
        "outputId": "13a91669-b470-44c0-feed-2e5bb624b1d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle API configured successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Make sure the .kaggle folder exists\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "\n",
        "# Move kaggle.json from /content to /root/.kaggle\n",
        "shutil.move(\"/content/kaggle.json\", \"/root/.kaggle/kaggle.json\")\n",
        "\n",
        "# Set correct permissions\n",
        "os.chmod(\"/root/.kaggle/kaggle.json\", 0o600)\n",
        "\n",
        "print(\"Kaggle API configured successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d trainingdatapro/computed-tomography-ct-of-the-brain\n",
        "!unzip computed-tomography-ct-of-the-brain.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ve7cSYJP4hT",
        "outputId": "4ff6efd7-e44c-4828-a52e-003e1853def1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/trainingdatapro/computed-tomography-ct-of-the-brain\n",
            "License(s): Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)\n",
            "Downloading computed-tomography-ct-of-the-brain.zip to /content\n",
            "  0% 0.00/66.0M [00:00<?, ?B/s]\n",
            "100% 66.0M/66.0M [00:00<00:00, 1.72GB/s]\n",
            "Archive:  computed-tomography-ct-of-the-brain.zip\n",
            "  inflating: ct_brain.csv            \n",
            "  inflating: files/aneurysm/0.dcm    \n",
            "  inflating: files/aneurysm/0.jpg    \n",
            "  inflating: files/aneurysm/1.dcm    \n",
            "  inflating: files/aneurysm/1.jpg    \n",
            "  inflating: files/aneurysm/10.dcm   \n",
            "  inflating: files/aneurysm/10.jpg   \n",
            "  inflating: files/aneurysm/11.dcm   \n",
            "  inflating: files/aneurysm/11.jpg   \n",
            "  inflating: files/aneurysm/12.dcm   \n",
            "  inflating: files/aneurysm/12.jpg   \n",
            "  inflating: files/aneurysm/13.dcm   \n",
            "  inflating: files/aneurysm/13.jpg   \n",
            "  inflating: files/aneurysm/14.dcm   \n",
            "  inflating: files/aneurysm/14.jpg   \n",
            "  inflating: files/aneurysm/15.dcm   \n",
            "  inflating: files/aneurysm/15.jpg   \n",
            "  inflating: files/aneurysm/16.dcm   \n",
            "  inflating: files/aneurysm/16.jpg   \n",
            "  inflating: files/aneurysm/17.dcm   \n",
            "  inflating: files/aneurysm/17.jpg   \n",
            "  inflating: files/aneurysm/18.dcm   \n",
            "  inflating: files/aneurysm/18.jpg   \n",
            "  inflating: files/aneurysm/19.dcm   \n",
            "  inflating: files/aneurysm/19.jpg   \n",
            "  inflating: files/aneurysm/2.dcm    \n",
            "  inflating: files/aneurysm/2.jpg    \n",
            "  inflating: files/aneurysm/20.dcm   \n",
            "  inflating: files/aneurysm/20.jpg   \n",
            "  inflating: files/aneurysm/21.dcm   \n",
            "  inflating: files/aneurysm/21.jpg   \n",
            "  inflating: files/aneurysm/22.dcm   \n",
            "  inflating: files/aneurysm/22.jpg   \n",
            "  inflating: files/aneurysm/23.dcm   \n",
            "  inflating: files/aneurysm/23.jpg   \n",
            "  inflating: files/aneurysm/24.dcm   \n",
            "  inflating: files/aneurysm/24.jpg   \n",
            "  inflating: files/aneurysm/25.dcm   \n",
            "  inflating: files/aneurysm/25.jpg   \n",
            "  inflating: files/aneurysm/26.dcm   \n",
            "  inflating: files/aneurysm/26.jpg   \n",
            "  inflating: files/aneurysm/27.dcm   \n",
            "  inflating: files/aneurysm/27.jpg   \n",
            "  inflating: files/aneurysm/28.dcm   \n",
            "  inflating: files/aneurysm/28.jpg   \n",
            "  inflating: files/aneurysm/29.dcm   \n",
            "  inflating: files/aneurysm/29.jpg   \n",
            "  inflating: files/aneurysm/3.dcm    \n",
            "  inflating: files/aneurysm/3.jpg    \n",
            "  inflating: files/aneurysm/30.dcm   \n",
            "  inflating: files/aneurysm/30.jpg   \n",
            "  inflating: files/aneurysm/31.dcm   \n",
            "  inflating: files/aneurysm/31.jpg   \n",
            "  inflating: files/aneurysm/32.dcm   \n",
            "  inflating: files/aneurysm/32.jpg   \n",
            "  inflating: files/aneurysm/33.dcm   \n",
            "  inflating: files/aneurysm/33.jpg   \n",
            "  inflating: files/aneurysm/34.dcm   \n",
            "  inflating: files/aneurysm/34.jpg   \n",
            "  inflating: files/aneurysm/35.dcm   \n",
            "  inflating: files/aneurysm/35.jpg   \n",
            "  inflating: files/aneurysm/36.dcm   \n",
            "  inflating: files/aneurysm/36.jpg   \n",
            "  inflating: files/aneurysm/37.dcm   \n",
            "  inflating: files/aneurysm/37.jpg   \n",
            "  inflating: files/aneurysm/38.dcm   \n",
            "  inflating: files/aneurysm/38.jpg   \n",
            "  inflating: files/aneurysm/39.dcm   \n",
            "  inflating: files/aneurysm/39.jpg   \n",
            "  inflating: files/aneurysm/4.dcm    \n",
            "  inflating: files/aneurysm/4.jpg    \n",
            "  inflating: files/aneurysm/40.dcm   \n",
            "  inflating: files/aneurysm/40.jpg   \n",
            "  inflating: files/aneurysm/41.dcm   \n",
            "  inflating: files/aneurysm/41.jpg   \n",
            "  inflating: files/aneurysm/42.dcm   \n",
            "  inflating: files/aneurysm/42.jpg   \n",
            "  inflating: files/aneurysm/43.dcm   \n",
            "  inflating: files/aneurysm/43.jpg   \n",
            "  inflating: files/aneurysm/44.dcm   \n",
            "  inflating: files/aneurysm/44.jpg   \n",
            "  inflating: files/aneurysm/45.dcm   \n",
            "  inflating: files/aneurysm/45.jpg   \n",
            "  inflating: files/aneurysm/46.dcm   \n",
            "  inflating: files/aneurysm/46.jpg   \n",
            "  inflating: files/aneurysm/47.dcm   \n",
            "  inflating: files/aneurysm/47.jpg   \n",
            "  inflating: files/aneurysm/48.dcm   \n",
            "  inflating: files/aneurysm/48.jpg   \n",
            "  inflating: files/aneurysm/49.dcm   \n",
            "  inflating: files/aneurysm/49.jpg   \n",
            "  inflating: files/aneurysm/5.dcm    \n",
            "  inflating: files/aneurysm/5.jpg    \n",
            "  inflating: files/aneurysm/50.dcm   \n",
            "  inflating: files/aneurysm/50.jpg   \n",
            "  inflating: files/aneurysm/51.dcm   \n",
            "  inflating: files/aneurysm/51.jpg   \n",
            "  inflating: files/aneurysm/52.dcm   \n",
            "  inflating: files/aneurysm/52.jpg   \n",
            "  inflating: files/aneurysm/53.dcm   \n",
            "  inflating: files/aneurysm/53.jpg   \n",
            "  inflating: files/aneurysm/54.dcm   \n",
            "  inflating: files/aneurysm/54.jpg   \n",
            "  inflating: files/aneurysm/55.dcm   \n",
            "  inflating: files/aneurysm/55.jpg   \n",
            "  inflating: files/aneurysm/56.dcm   \n",
            "  inflating: files/aneurysm/56.jpg   \n",
            "  inflating: files/aneurysm/57.dcm   \n",
            "  inflating: files/aneurysm/57.jpg   \n",
            "  inflating: files/aneurysm/58.dcm   \n",
            "  inflating: files/aneurysm/58.jpg   \n",
            "  inflating: files/aneurysm/59.dcm   \n",
            "  inflating: files/aneurysm/59.jpg   \n",
            "  inflating: files/aneurysm/6.dcm    \n",
            "  inflating: files/aneurysm/6.jpg    \n",
            "  inflating: files/aneurysm/60.dcm   \n",
            "  inflating: files/aneurysm/60.jpg   \n",
            "  inflating: files/aneurysm/61.dcm   \n",
            "  inflating: files/aneurysm/61.jpg   \n",
            "  inflating: files/aneurysm/62.dcm   \n",
            "  inflating: files/aneurysm/62.jpg   \n",
            "  inflating: files/aneurysm/63.dcm   \n",
            "  inflating: files/aneurysm/63.jpg   \n",
            "  inflating: files/aneurysm/64.dcm   \n",
            "  inflating: files/aneurysm/64.jpg   \n",
            "  inflating: files/aneurysm/65.dcm   \n",
            "  inflating: files/aneurysm/65.jpg   \n",
            "  inflating: files/aneurysm/66.dcm   \n",
            "  inflating: files/aneurysm/66.jpg   \n",
            "  inflating: files/aneurysm/67.dcm   \n",
            "  inflating: files/aneurysm/67.jpg   \n",
            "  inflating: files/aneurysm/68.dcm   \n",
            "  inflating: files/aneurysm/68.jpg   \n",
            "  inflating: files/aneurysm/69.dcm   \n",
            "  inflating: files/aneurysm/69.jpg   \n",
            "  inflating: files/aneurysm/7.dcm    \n",
            "  inflating: files/aneurysm/7.jpg    \n",
            "  inflating: files/aneurysm/70.dcm   \n",
            "  inflating: files/aneurysm/70.jpg   \n",
            "  inflating: files/aneurysm/71.dcm   \n",
            "  inflating: files/aneurysm/71.jpg   \n",
            "  inflating: files/aneurysm/72.dcm   \n",
            "  inflating: files/aneurysm/72.jpg   \n",
            "  inflating: files/aneurysm/73.dcm   \n",
            "  inflating: files/aneurysm/73.jpg   \n",
            "  inflating: files/aneurysm/74.dcm   \n",
            "  inflating: files/aneurysm/74.jpg   \n",
            "  inflating: files/aneurysm/75.dcm   \n",
            "  inflating: files/aneurysm/75.jpg   \n",
            "  inflating: files/aneurysm/76.dcm   \n",
            "  inflating: files/aneurysm/76.jpg   \n",
            "  inflating: files/aneurysm/77.dcm   \n",
            "  inflating: files/aneurysm/77.jpg   \n",
            "  inflating: files/aneurysm/78.dcm   \n",
            "  inflating: files/aneurysm/78.jpg   \n",
            "  inflating: files/aneurysm/79.dcm   \n",
            "  inflating: files/aneurysm/79.jpg   \n",
            "  inflating: files/aneurysm/8.dcm    \n",
            "  inflating: files/aneurysm/8.jpg    \n",
            "  inflating: files/aneurysm/80.dcm   \n",
            "  inflating: files/aneurysm/80.jpg   \n",
            "  inflating: files/aneurysm/81.dcm   \n",
            "  inflating: files/aneurysm/81.jpg   \n",
            "  inflating: files/aneurysm/82.dcm   \n",
            "  inflating: files/aneurysm/82.jpg   \n",
            "  inflating: files/aneurysm/83.dcm   \n",
            "  inflating: files/aneurysm/83.jpg   \n",
            "  inflating: files/aneurysm/9.dcm    \n",
            "  inflating: files/aneurysm/9.jpg    \n",
            "  inflating: files/cancer/0.dcm      \n",
            "  inflating: files/cancer/0.jpg      \n",
            "  inflating: files/cancer/1.dcm      \n",
            "  inflating: files/cancer/1.jpg      \n",
            "  inflating: files/cancer/10.dcm     \n",
            "  inflating: files/cancer/10.jpg     \n",
            "  inflating: files/cancer/11.dcm     \n",
            "  inflating: files/cancer/11.jpg     \n",
            "  inflating: files/cancer/12.dcm     \n",
            "  inflating: files/cancer/12.jpg     \n",
            "  inflating: files/cancer/13.dcm     \n",
            "  inflating: files/cancer/13.jpg     \n",
            "  inflating: files/cancer/14.dcm     \n",
            "  inflating: files/cancer/14.jpg     \n",
            "  inflating: files/cancer/15.dcm     \n",
            "  inflating: files/cancer/15.jpg     \n",
            "  inflating: files/cancer/16.dcm     \n",
            "  inflating: files/cancer/16.jpg     \n",
            "  inflating: files/cancer/17.dcm     \n",
            "  inflating: files/cancer/17.jpg     \n",
            "  inflating: files/cancer/18.dcm     \n",
            "  inflating: files/cancer/18.jpg     \n",
            "  inflating: files/cancer/19.dcm     \n",
            "  inflating: files/cancer/19.jpg     \n",
            "  inflating: files/cancer/2.dcm      \n",
            "  inflating: files/cancer/2.jpg      \n",
            "  inflating: files/cancer/20.dcm     \n",
            "  inflating: files/cancer/20.jpg     \n",
            "  inflating: files/cancer/21.dcm     \n",
            "  inflating: files/cancer/21.jpg     \n",
            "  inflating: files/cancer/22.dcm     \n",
            "  inflating: files/cancer/22.jpg     \n",
            "  inflating: files/cancer/23.dcm     \n",
            "  inflating: files/cancer/23.jpg     \n",
            "  inflating: files/cancer/24.dcm     \n",
            "  inflating: files/cancer/24.jpg     \n",
            "  inflating: files/cancer/25.dcm     \n",
            "  inflating: files/cancer/25.jpg     \n",
            "  inflating: files/cancer/26.dcm     \n",
            "  inflating: files/cancer/26.jpg     \n",
            "  inflating: files/cancer/27.dcm     \n",
            "  inflating: files/cancer/27.jpg     \n",
            "  inflating: files/cancer/28.dcm     \n",
            "  inflating: files/cancer/28.jpg     \n",
            "  inflating: files/cancer/29.dcm     \n",
            "  inflating: files/cancer/29.jpg     \n",
            "  inflating: files/cancer/3.dcm      \n",
            "  inflating: files/cancer/3.jpg      \n",
            "  inflating: files/cancer/30.dcm     \n",
            "  inflating: files/cancer/30.jpg     \n",
            "  inflating: files/cancer/31.dcm     \n",
            "  inflating: files/cancer/31.jpg     \n",
            "  inflating: files/cancer/32.dcm     \n",
            "  inflating: files/cancer/32.jpg     \n",
            "  inflating: files/cancer/33.dcm     \n",
            "  inflating: files/cancer/33.jpg     \n",
            "  inflating: files/cancer/34.dcm     \n",
            "  inflating: files/cancer/34.jpg     \n",
            "  inflating: files/cancer/35.dcm     \n",
            "  inflating: files/cancer/35.jpg     \n",
            "  inflating: files/cancer/36.dcm     \n",
            "  inflating: files/cancer/36.jpg     \n",
            "  inflating: files/cancer/37.dcm     \n",
            "  inflating: files/cancer/37.jpg     \n",
            "  inflating: files/cancer/38.dcm     \n",
            "  inflating: files/cancer/38.jpg     \n",
            "  inflating: files/cancer/39.dcm     \n",
            "  inflating: files/cancer/39.jpg     \n",
            "  inflating: files/cancer/4.dcm      \n",
            "  inflating: files/cancer/4.jpg      \n",
            "  inflating: files/cancer/40.dcm     \n",
            "  inflating: files/cancer/40.jpg     \n",
            "  inflating: files/cancer/41.dcm     \n",
            "  inflating: files/cancer/41.jpg     \n",
            "  inflating: files/cancer/42.dcm     \n",
            "  inflating: files/cancer/42.jpg     \n",
            "  inflating: files/cancer/43.dcm     \n",
            "  inflating: files/cancer/43.jpg     \n",
            "  inflating: files/cancer/44.dcm     \n",
            "  inflating: files/cancer/44.jpg     \n",
            "  inflating: files/cancer/45.dcm     \n",
            "  inflating: files/cancer/45.jpg     \n",
            "  inflating: files/cancer/46.dcm     \n",
            "  inflating: files/cancer/46.jpg     \n",
            "  inflating: files/cancer/47.dcm     \n",
            "  inflating: files/cancer/47.jpg     \n",
            "  inflating: files/cancer/48.dcm     \n",
            "  inflating: files/cancer/48.jpg     \n",
            "  inflating: files/cancer/49.dcm     \n",
            "  inflating: files/cancer/49.jpg     \n",
            "  inflating: files/cancer/5.dcm      \n",
            "  inflating: files/cancer/5.jpg      \n",
            "  inflating: files/cancer/50.dcm     \n",
            "  inflating: files/cancer/50.jpg     \n",
            "  inflating: files/cancer/51.dcm     \n",
            "  inflating: files/cancer/51.jpg     \n",
            "  inflating: files/cancer/52.dcm     \n",
            "  inflating: files/cancer/52.jpg     \n",
            "  inflating: files/cancer/53.dcm     \n",
            "  inflating: files/cancer/53.jpg     \n",
            "  inflating: files/cancer/54.dcm     \n",
            "  inflating: files/cancer/54.jpg     \n",
            "  inflating: files/cancer/55.dcm     \n",
            "  inflating: files/cancer/55.jpg     \n",
            "  inflating: files/cancer/56.dcm     \n",
            "  inflating: files/cancer/56.jpg     \n",
            "  inflating: files/cancer/57.dcm     \n",
            "  inflating: files/cancer/57.jpg     \n",
            "  inflating: files/cancer/58.dcm     \n",
            "  inflating: files/cancer/58.jpg     \n",
            "  inflating: files/cancer/59.dcm     \n",
            "  inflating: files/cancer/59.jpg     \n",
            "  inflating: files/cancer/6.dcm      \n",
            "  inflating: files/cancer/6.jpg      \n",
            "  inflating: files/cancer/60.dcm     \n",
            "  inflating: files/cancer/60.jpg     \n",
            "  inflating: files/cancer/61.dcm     \n",
            "  inflating: files/cancer/61.jpg     \n",
            "  inflating: files/cancer/62.dcm     \n",
            "  inflating: files/cancer/62.jpg     \n",
            "  inflating: files/cancer/63.dcm     \n",
            "  inflating: files/cancer/63.jpg     \n",
            "  inflating: files/cancer/64.dcm     \n",
            "  inflating: files/cancer/64.jpg     \n",
            "  inflating: files/cancer/65.dcm     \n",
            "  inflating: files/cancer/65.jpg     \n",
            "  inflating: files/cancer/66.dcm     \n",
            "  inflating: files/cancer/66.jpg     \n",
            "  inflating: files/cancer/67.dcm     \n",
            "  inflating: files/cancer/67.jpg     \n",
            "  inflating: files/cancer/68.dcm     \n",
            "  inflating: files/cancer/68.jpg     \n",
            "  inflating: files/cancer/69.dcm     \n",
            "  inflating: files/cancer/69.jpg     \n",
            "  inflating: files/cancer/7.dcm      \n",
            "  inflating: files/cancer/7.jpg      \n",
            "  inflating: files/cancer/70.dcm     \n",
            "  inflating: files/cancer/70.jpg     \n",
            "  inflating: files/cancer/71.dcm     \n",
            "  inflating: files/cancer/71.jpg     \n",
            "  inflating: files/cancer/72.dcm     \n",
            "  inflating: files/cancer/72.jpg     \n",
            "  inflating: files/cancer/73.dcm     \n",
            "  inflating: files/cancer/73.jpg     \n",
            "  inflating: files/cancer/74.dcm     \n",
            "  inflating: files/cancer/74.jpg     \n",
            "  inflating: files/cancer/75.dcm     \n",
            "  inflating: files/cancer/75.jpg     \n",
            "  inflating: files/cancer/76.dcm     \n",
            "  inflating: files/cancer/76.jpg     \n",
            "  inflating: files/cancer/77.dcm     \n",
            "  inflating: files/cancer/77.jpg     \n",
            "  inflating: files/cancer/78.dcm     \n",
            "  inflating: files/cancer/78.jpg     \n",
            "  inflating: files/cancer/79.dcm     \n",
            "  inflating: files/cancer/79.jpg     \n",
            "  inflating: files/cancer/8.dcm      \n",
            "  inflating: files/cancer/8.jpg      \n",
            "  inflating: files/cancer/80.dcm     \n",
            "  inflating: files/cancer/80.jpg     \n",
            "  inflating: files/cancer/81.dcm     \n",
            "  inflating: files/cancer/81.jpg     \n",
            "  inflating: files/cancer/82.dcm     \n",
            "  inflating: files/cancer/82.jpg     \n",
            "  inflating: files/cancer/83.dcm     \n",
            "  inflating: files/cancer/83.jpg     \n",
            "  inflating: files/cancer/84.dcm     \n",
            "  inflating: files/cancer/84.jpg     \n",
            "  inflating: files/cancer/85.dcm     \n",
            "  inflating: files/cancer/85.jpg     \n",
            "  inflating: files/cancer/86.dcm     \n",
            "  inflating: files/cancer/86.jpg     \n",
            "  inflating: files/cancer/87.dcm     \n",
            "  inflating: files/cancer/87.jpg     \n",
            "  inflating: files/cancer/88.dcm     \n",
            "  inflating: files/cancer/88.jpg     \n",
            "  inflating: files/cancer/89.dcm     \n",
            "  inflating: files/cancer/89.jpg     \n",
            "  inflating: files/cancer/9.dcm      \n",
            "  inflating: files/cancer/9.jpg      \n",
            "  inflating: files/cancer/90.dcm     \n",
            "  inflating: files/cancer/90.jpg     \n",
            "  inflating: files/tumor/0.dcm       \n",
            "  inflating: files/tumor/0.jpg       \n",
            "  inflating: files/tumor/1.dcm       \n",
            "  inflating: files/tumor/1.jpg       \n",
            "  inflating: files/tumor/10.dcm      \n",
            "  inflating: files/tumor/10.jpg      \n",
            "  inflating: files/tumor/11.dcm      \n",
            "  inflating: files/tumor/11.jpg      \n",
            "  inflating: files/tumor/12.dcm      \n",
            "  inflating: files/tumor/12.jpg      \n",
            "  inflating: files/tumor/13.dcm      \n",
            "  inflating: files/tumor/13.jpg      \n",
            "  inflating: files/tumor/14.dcm      \n",
            "  inflating: files/tumor/14.jpg      \n",
            "  inflating: files/tumor/15.dcm      \n",
            "  inflating: files/tumor/15.jpg      \n",
            "  inflating: files/tumor/16.dcm      \n",
            "  inflating: files/tumor/16.jpg      \n",
            "  inflating: files/tumor/17.dcm      \n",
            "  inflating: files/tumor/17.jpg      \n",
            "  inflating: files/tumor/18.dcm      \n",
            "  inflating: files/tumor/18.jpg      \n",
            "  inflating: files/tumor/19.dcm      \n",
            "  inflating: files/tumor/19.jpg      \n",
            "  inflating: files/tumor/2.dcm       \n",
            "  inflating: files/tumor/2.jpg       \n",
            "  inflating: files/tumor/20.dcm      \n",
            "  inflating: files/tumor/20.jpg      \n",
            "  inflating: files/tumor/21.dcm      \n",
            "  inflating: files/tumor/21.jpg      \n",
            "  inflating: files/tumor/22.dcm      \n",
            "  inflating: files/tumor/22.jpg      \n",
            "  inflating: files/tumor/23.dcm      \n",
            "  inflating: files/tumor/23.jpg      \n",
            "  inflating: files/tumor/24.dcm      \n",
            "  inflating: files/tumor/24.jpg      \n",
            "  inflating: files/tumor/25.dcm      \n",
            "  inflating: files/tumor/25.jpg      \n",
            "  inflating: files/tumor/26.dcm      \n",
            "  inflating: files/tumor/26.jpg      \n",
            "  inflating: files/tumor/27.dcm      \n",
            "  inflating: files/tumor/27.jpg      \n",
            "  inflating: files/tumor/28.dcm      \n",
            "  inflating: files/tumor/28.jpg      \n",
            "  inflating: files/tumor/29.dcm      \n",
            "  inflating: files/tumor/29.jpg      \n",
            "  inflating: files/tumor/3.dcm       \n",
            "  inflating: files/tumor/3.jpg       \n",
            "  inflating: files/tumor/30.dcm      \n",
            "  inflating: files/tumor/30.jpg      \n",
            "  inflating: files/tumor/31.dcm      \n",
            "  inflating: files/tumor/31.jpg      \n",
            "  inflating: files/tumor/32.dcm      \n",
            "  inflating: files/tumor/32.jpg      \n",
            "  inflating: files/tumor/33.dcm      \n",
            "  inflating: files/tumor/33.jpg      \n",
            "  inflating: files/tumor/34.dcm      \n",
            "  inflating: files/tumor/34.jpg      \n",
            "  inflating: files/tumor/35.dcm      \n",
            "  inflating: files/tumor/35.jpg      \n",
            "  inflating: files/tumor/36.dcm      \n",
            "  inflating: files/tumor/36.jpg      \n",
            "  inflating: files/tumor/37.dcm      \n",
            "  inflating: files/tumor/37.jpg      \n",
            "  inflating: files/tumor/38.dcm      \n",
            "  inflating: files/tumor/38.jpg      \n",
            "  inflating: files/tumor/39.dcm      \n",
            "  inflating: files/tumor/39.jpg      \n",
            "  inflating: files/tumor/4.dcm       \n",
            "  inflating: files/tumor/4.jpg       \n",
            "  inflating: files/tumor/40.dcm      \n",
            "  inflating: files/tumor/40.jpg      \n",
            "  inflating: files/tumor/41.dcm      \n",
            "  inflating: files/tumor/41.jpg      \n",
            "  inflating: files/tumor/42.dcm      \n",
            "  inflating: files/tumor/42.jpg      \n",
            "  inflating: files/tumor/43.dcm      \n",
            "  inflating: files/tumor/43.jpg      \n",
            "  inflating: files/tumor/44.dcm      \n",
            "  inflating: files/tumor/44.jpg      \n",
            "  inflating: files/tumor/45.dcm      \n",
            "  inflating: files/tumor/45.jpg      \n",
            "  inflating: files/tumor/46.dcm      \n",
            "  inflating: files/tumor/46.jpg      \n",
            "  inflating: files/tumor/47.dcm      \n",
            "  inflating: files/tumor/47.jpg      \n",
            "  inflating: files/tumor/48.dcm      \n",
            "  inflating: files/tumor/48.jpg      \n",
            "  inflating: files/tumor/49.dcm      \n",
            "  inflating: files/tumor/49.jpg      \n",
            "  inflating: files/tumor/5.dcm       \n",
            "  inflating: files/tumor/5.jpg       \n",
            "  inflating: files/tumor/50.dcm      \n",
            "  inflating: files/tumor/50.jpg      \n",
            "  inflating: files/tumor/51.dcm      \n",
            "  inflating: files/tumor/51.jpg      \n",
            "  inflating: files/tumor/52.dcm      \n",
            "  inflating: files/tumor/52.jpg      \n",
            "  inflating: files/tumor/53.dcm      \n",
            "  inflating: files/tumor/53.jpg      \n",
            "  inflating: files/tumor/54.dcm      \n",
            "  inflating: files/tumor/54.jpg      \n",
            "  inflating: files/tumor/55.dcm      \n",
            "  inflating: files/tumor/55.jpg      \n",
            "  inflating: files/tumor/56.dcm      \n",
            "  inflating: files/tumor/56.jpg      \n",
            "  inflating: files/tumor/57.dcm      \n",
            "  inflating: files/tumor/57.jpg      \n",
            "  inflating: files/tumor/58.dcm      \n",
            "  inflating: files/tumor/58.jpg      \n",
            "  inflating: files/tumor/59.dcm      \n",
            "  inflating: files/tumor/59.jpg      \n",
            "  inflating: files/tumor/6.dcm       \n",
            "  inflating: files/tumor/6.jpg       \n",
            "  inflating: files/tumor/60.dcm      \n",
            "  inflating: files/tumor/60.jpg      \n",
            "  inflating: files/tumor/61.dcm      \n",
            "  inflating: files/tumor/61.jpg      \n",
            "  inflating: files/tumor/62.dcm      \n",
            "  inflating: files/tumor/62.jpg      \n",
            "  inflating: files/tumor/63.dcm      \n",
            "  inflating: files/tumor/63.jpg      \n",
            "  inflating: files/tumor/64.dcm      \n",
            "  inflating: files/tumor/64.jpg      \n",
            "  inflating: files/tumor/65.dcm      \n",
            "  inflating: files/tumor/65.jpg      \n",
            "  inflating: files/tumor/66.dcm      \n",
            "  inflating: files/tumor/66.jpg      \n",
            "  inflating: files/tumor/67.dcm      \n",
            "  inflating: files/tumor/67.jpg      \n",
            "  inflating: files/tumor/68.dcm      \n",
            "  inflating: files/tumor/68.jpg      \n",
            "  inflating: files/tumor/69.dcm      \n",
            "  inflating: files/tumor/69.jpg      \n",
            "  inflating: files/tumor/7.dcm       \n",
            "  inflating: files/tumor/7.jpg       \n",
            "  inflating: files/tumor/70.dcm      \n",
            "  inflating: files/tumor/70.jpg      \n",
            "  inflating: files/tumor/71.dcm      \n",
            "  inflating: files/tumor/71.jpg      \n",
            "  inflating: files/tumor/72.dcm      \n",
            "  inflating: files/tumor/72.jpg      \n",
            "  inflating: files/tumor/73.dcm      \n",
            "  inflating: files/tumor/73.jpg      \n",
            "  inflating: files/tumor/74.dcm      \n",
            "  inflating: files/tumor/74.jpg      \n",
            "  inflating: files/tumor/75.dcm      \n",
            "  inflating: files/tumor/75.jpg      \n",
            "  inflating: files/tumor/76.dcm      \n",
            "  inflating: files/tumor/76.jpg      \n",
            "  inflating: files/tumor/77.dcm      \n",
            "  inflating: files/tumor/77.jpg      \n",
            "  inflating: files/tumor/78.dcm      \n",
            "  inflating: files/tumor/78.jpg      \n",
            "  inflating: files/tumor/79.dcm      \n",
            "  inflating: files/tumor/79.jpg      \n",
            "  inflating: files/tumor/8.dcm       \n",
            "  inflating: files/tumor/8.jpg       \n",
            "  inflating: files/tumor/80.dcm      \n",
            "  inflating: files/tumor/80.jpg      \n",
            "  inflating: files/tumor/81.dcm      \n",
            "  inflating: files/tumor/81.jpg      \n",
            "  inflating: files/tumor/82.dcm      \n",
            "  inflating: files/tumor/82.jpg      \n",
            "  inflating: files/tumor/83.dcm      \n",
            "  inflating: files/tumor/83.jpg      \n",
            "  inflating: files/tumor/9.dcm       \n",
            "  inflating: files/tumor/9.jpg       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n"
      ],
      "metadata": {
        "id": "wsiKAeBHP6gA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_PATH = \"/content/ct_brain.csv\"\n",
        "BASE_PATH = \"/content/files\"\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# تعديل المسارات لتكون كاملة\n",
        "df['jpg'] = df['jpg'].apply(lambda x: os.path.join(BASE_PATH, x.strip('/')) if pd.notna(x) else np.nan)\n",
        "df['dcm'] = df['dcm'].apply(lambda x: os.path.join(BASE_PATH, x.strip('/')) if pd.notna(x) else np.nan)\n",
        "\n",
        "# تحويل النوع إلى Binary Label: 1 = Aneurysm, 0 = غيره\n",
        "df['label'] = (df['type'] == 'aneurysm').astype(int)\n",
        "\n",
        "print(df[['type','label']].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fNl8-vOQRbu",
        "outputId": "dddee26c-b3c5-4658-9893-d1cc95a872f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type      label\n",
            "cancer    0        90\n",
            "aneurysm  1        83\n",
            "tumor     0        83\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_jpg_image(jpg_path):\n",
        "    img = cv2.imread(jpg_path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (224,224))\n",
        "    img = img / 255.0\n",
        "    img = np.stack([img]*3, axis=-1)  # تحويل الرمادي إلى RGB\n",
        "    return img\n",
        "\n",
        "def dicom_to_image(dcm_path):\n",
        "    import pydicom\n",
        "    dcm = pydicom.dcmread(dcm_path)\n",
        "    img = dcm.pixel_array.astype(np.float32)\n",
        "    img = np.clip(img, -100, 400)  # windowing\n",
        "    img = (img - img.min()) / (img.max() - img.min())\n",
        "    img = cv2.resize(img, (224,224))\n",
        "    img = np.stack([img]*3, axis=-1)\n",
        "    return img\n",
        "\n",
        "def preprocess_image(row):\n",
        "    path = row['jpg'] if pd.notna(row['jpg']) else row['dcm']\n",
        "    if path.endswith('.jpg'):\n",
        "        img = load_jpg_image(path)\n",
        "    else:\n",
        "        img = dicom_to_image(path)\n",
        "    label = row['label']\n",
        "    return img, label\n"
      ],
      "metadata": {
        "id": "3xFOYx-kQUfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def df_to_dataset(df, batch_size=16, shuffle=True, augment=False):\n",
        "    images, labels = [], []\n",
        "    for _, row in df.iterrows():\n",
        "        try:\n",
        "            img, label = preprocess_image(row)\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "        except (FileNotFoundError, ValueError):\n",
        "            continue\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    if augment:\n",
        "        datagen = ImageDataGenerator(\n",
        "            rotation_range=10,\n",
        "            zoom_range=0.1,\n",
        "            horizontal_flip=True,\n",
        "            brightness_range=[0.9, 1.1]\n",
        "        )\n",
        "    else:\n",
        "        datagen = ImageDataGenerator()\n",
        "\n",
        "    dataset = datagen.flow(images, labels, batch_size=batch_size, shuffle=shuffle)\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "yUkeMOk5QZWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['label'], random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)\n",
        "\n",
        "# حساب أوزان الفئات لموازنة البيانات\n",
        "weights = class_weight.compute_class_weight('balanced', classes=np.unique(train_df['label']), y=train_df['label'])\n",
        "class_weights = dict(enumerate(weights))\n",
        "\n",
        "# إنشاء Datasets\n",
        "train_dataset = df_to_dataset(train_df, batch_size=16, augment=True)\n",
        "val_dataset   = df_to_dataset(val_df, batch_size=16, shuffle=False)\n",
        "test_dataset  = df_to_dataset(test_df, batch_size=16, shuffle=False)\n"
      ],
      "metadata": {
        "id": "czE0jGVXQcvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = Xception(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "base_model.trainable = False  # تثبيت الطبقات pretrained\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "A90bbQHmQfjg",
        "outputId": "fb089d81-3a9e-4bce-808b-704ee26986d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ xception (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m20,861,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m2,049\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ xception (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,863,529\u001b[0m (79.59 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,863,529</span> (79.59 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,049\u001b[0m (8.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> (8.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,861,480\u001b[0m (79.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> (79.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xZhARgU4QnLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, min_lr=1e-6)\n"
      ],
      "metadata": {
        "id": "5OaR1T0uQrAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=30,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stop, reduce_lr]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8fmX6j1Qj4i",
        "outputId": "d9d74e5b-b143-430a-d7a3-e7a6405b7ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 4s/step - accuracy: 0.4063 - loss: 0.7490 - val_accuracy: 0.3684 - val_loss: 0.7361 - learning_rate: 1.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.4403 - loss: 0.7246 - val_accuracy: 0.3421 - val_loss: 0.7415 - learning_rate: 1.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3s/step - accuracy: 0.4553 - loss: 0.6921 - val_accuracy: 0.3684 - val_loss: 0.7565 - learning_rate: 1.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.3988 - loss: 0.7009 - val_accuracy: 0.3158 - val_loss: 0.7835 - learning_rate: 1.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.4571 - loss: 0.6663 - val_accuracy: 0.3158 - val_loss: 0.7884 - learning_rate: 3.0000e-05\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4s/step - accuracy: 0.4154 - loss: 0.7526 - val_accuracy: 0.3158 - val_loss: 0.7961 - learning_rate: 3.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-50]:  # تجميد الطبقات السفلى\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_ft = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=10,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stop, reduce_lr]\n",
        ")\n"
      ],
      "metadata": {
        "id": "I47Tk_jfQrjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(\"Test Accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "id": "nmCSzZh0Q4uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "#  استيراد المكتبات الضرورية\n",
        "# ===============================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import pydicom\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# ===============================\n",
        "#  إعداد البيانات\n",
        "# ===============================\n",
        "CSV_PATH = \"/content/ct_brain.csv\"\n",
        "BASE_PATH = \"/content/files\"\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# تعديل مسارات الصور لتكون كاملة\n",
        "df['jpg'] = df['jpg'].apply(lambda x: os.path.join(BASE_PATH, x.strip('/')) if pd.notna(x) else np.nan)\n",
        "df['dcm'] = df['dcm'].apply(lambda x: os.path.join(BASE_PATH, x.strip('/')) if pd.notna(x) else np.nan)\n",
        "\n",
        "# ===============================\n",
        "#  اختيار فقط فئتين: aneurysm و tumor\n",
        "# ===============================\n",
        "df_binary = df[df['type'].isin(['aneurysm', 'tumor'])].copy()\n",
        "df_binary['label'] = (df_binary['type'] == 'aneurysm').astype(int)\n",
        "\n",
        "print(\"عدد العينات لكل فئة:\")\n",
        "print(df_binary['type'].value_counts())\n",
        "\n",
        "# ===============================\n",
        "#  تقسيم البيانات: Train / Val / Test\n",
        "# ===============================\n",
        "train_df, temp_df = train_test_split(df_binary, test_size=0.3, stratify=df_binary['label'], random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)\n",
        "\n",
        "# ===============================\n",
        "#  تعريف preprocessing للصور\n",
        "# ===============================\n",
        "IMG_SIZE = (224,224)\n",
        "\n",
        "def dicom_to_image(dcm_path):\n",
        "    \"\"\"تحويل DICOM إلى صورة grayscale\"\"\"\n",
        "    if not os.path.exists(dcm_path):\n",
        "        raise FileNotFoundError(f\"DICOM file not found: {dcm_path}\")\n",
        "    dcm = pydicom.dcmread(dcm_path)\n",
        "    img = dcm.pixel_array.astype(np.float32)\n",
        "    img = np.clip(img, -100, 400)  # windowing\n",
        "    img = (img - img.min()) / (img.max() - img.min())\n",
        "    img = (img * 255).astype(np.uint8)\n",
        "    img = cv2.resize(img, IMG_SIZE)\n",
        "    return img\n",
        "\n",
        "def load_jpg_image(jpg_path):\n",
        "    \"\"\"قراءة صور JPG وتحويلها إلى grayscale\"\"\"\n",
        "    if not os.path.exists(jpg_path):\n",
        "        raise FileNotFoundError(f\"JPG file not found: {jpg_path}\")\n",
        "    img = cv2.imread(jpg_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Unable to read image: {jpg_path}\")\n",
        "    img = cv2.resize(img, IMG_SIZE)\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "def preprocess_image(row):\n",
        "    \"\"\"اختر المصدر الصحيح وحول الصورة إلى RGB 3 Channels\"\"\"\n",
        "    path = row['jpg'] if pd.notna(row['jpg']) else row['dcm']\n",
        "    if path.endswith('.jpg'):\n",
        "        img = load_jpg_image(path)\n",
        "    else:\n",
        "        img = dicom_to_image(path) / 255.0\n",
        "    img = np.stack([img]*3, axis=-1)  # grayscale -> RGB\n",
        "    label = row['label']\n",
        "    return img, label\n",
        "\n",
        "# ===============================\n",
        "#  Data Augmentation\n",
        "# ===============================\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.9,1.1]\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator()\n",
        "\n",
        "def df_to_dataset(df, datagen, batch_size=16, shuffle=True):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for _, row in df.iterrows():\n",
        "        try:\n",
        "            img, label = preprocess_image(row)\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "        except (FileNotFoundError, ValueError) as e:\n",
        "            print(\"Skipping file:\", e)\n",
        "            continue\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "    if len(images) == 0:\n",
        "        raise ValueError(\"No images found. Check paths.\")\n",
        "    dataset = datagen.flow(images, labels, batch_size=batch_size, shuffle=shuffle)\n",
        "    return dataset\n",
        "\n",
        "train_dataset = df_to_dataset(train_df, train_datagen)\n",
        "val_dataset   = df_to_dataset(val_df, val_test_datagen, shuffle=False)\n",
        "test_dataset  = df_to_dataset(test_df, val_test_datagen, shuffle=False)\n",
        "\n",
        "# ===============================\n",
        "#  حساب Class Weights لتوازن التدريب\n",
        "# ===============================\n",
        "class_weights_values = class_weight.compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(train_df['label']),\n",
        "    y=train_df['label']\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights_values))\n",
        "\n",
        "# ===============================\n",
        "#  بناء نموذج Xception مع Fine-Tuning\n",
        "# ===============================\n",
        "base_model = Xception(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(224,224,3)\n",
        ")\n",
        "base_model.trainable = True  # fine-tune جميع الطبقات\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')  # binary classification\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# ===============================\n",
        "#  Callbacks\n",
        "# ===============================\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr  = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
        "\n",
        "# ===============================\n",
        "#  تدريب النموذج\n",
        "# ===============================\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=30,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stop, reduce_lr]\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "#  تقييم النموذج على Test Set\n",
        "# ===============================\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(\"Test Accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "SWoXWBUsSin1",
        "outputId": "790e56cb-d51b-404d-f406-f4e216e43e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "عدد العينات لكل فئة:\n",
            "type\n",
            "aneurysm    83\n",
            "tumor       83\n",
            "Name: count, dtype: int64\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ xception (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m20,861,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m2,049\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ xception (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,863,529\u001b[0m (79.59 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,863,529</span> (79.59 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,809,001\u001b[0m (79.38 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,809,001</span> (79.38 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m54,528\u001b[0m (213.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,528</span> (213.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 7s/step - accuracy: 0.6375 - loss: 0.6323 - val_accuracy: 0.5200 - val_loss: 0.7789 - learning_rate: 1.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 239ms/step - accuracy: 0.7207 - loss: 0.5528 - val_accuracy: 0.5200 - val_loss: 0.8887 - learning_rate: 1.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 278ms/step - accuracy: 0.6344 - loss: 0.5611 - val_accuracy: 0.5200 - val_loss: 0.9257 - learning_rate: 1.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 249ms/step - accuracy: 0.7385 - loss: 0.5107 - val_accuracy: 0.5200 - val_loss: 0.9518 - learning_rate: 1.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 317ms/step - accuracy: 0.7562 - loss: 0.4866 - val_accuracy: 0.5200 - val_loss: 0.9147 - learning_rate: 5.0000e-05\n",
            "Epoch 6/30\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 245ms/step - accuracy: 0.7214 - loss: 0.5065 - val_accuracy: 0.5200 - val_loss: 0.8680 - learning_rate: 5.0000e-05\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.4867 - loss: 0.8181\n",
            "Test Accuracy: 0.47999998927116394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pydicom"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7DohxPISqFG",
        "outputId": "cc7dfd06-169b-41d8-83d7-0d04000dd57b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydicom\n",
            "  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Downloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m1.7/2.4 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = False  # freeze first\n",
        "# تدريب الطبقات العليا فقط\n",
        "model.fit(train_dataset, validation_data=val_dataset, epochs=5)\n",
        "# ثم افعل fine-tuning جزئي:\n",
        "base_model.trainable = True\n",
        "# تحديد طبقات عُليا فقط للتدريب\n",
        "for layer in base_model.layers[:-50]:\n",
        "    layer.trainable = False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn39893dStn7",
        "outputId": "95741525-0186-4932-b0bd-4c88275db3c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 743ms/step - accuracy: 0.5260 - loss: 0.6054 - val_accuracy: 0.5200 - val_loss: 0.7896\n",
            "Epoch 2/5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - accuracy: 0.4917 - loss: 0.6315 - val_accuracy: 0.5200 - val_loss: 0.8040\n",
            "Epoch 3/5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.4501 - loss: 0.6620 - val_accuracy: 0.5200 - val_loss: 0.8205\n",
            "Epoch 4/5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - accuracy: 0.5904 - loss: 0.6145 - val_accuracy: 0.5200 - val_loss: 0.8364\n",
            "Epoch 5/5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 307ms/step - accuracy: 0.5341 - loss: 0.5850 - val_accuracy: 0.5200 - val_loss: 0.8525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import pydicom\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "# --------------------------\n",
        "# 1. Load and filter dataset\n",
        "# --------------------------\n",
        "CSV_PATH = \"/content/ct_brain.csv\"\n",
        "BASE_PATH = \"/content/files\"\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# إصلاح المسارات\n",
        "df['jpg'] = df['jpg'].apply(lambda x: os.path.join(BASE_PATH, x.strip('/')) if pd.notna(x) else np.nan)\n",
        "df['dcm'] = df['dcm'].apply(lambda x: os.path.join(BASE_PATH, x.strip('/')) if pd.notna(x) else np.nan)\n",
        "\n",
        "# اختيار الفئتين فقط\n",
        "df_binary = df[df['type'].isin(['aneurysm', 'tumor'])].copy()\n",
        "df_binary['label'] = (df_binary['type'] == 'aneurysm').astype(int)\n",
        "\n",
        "# --------------------------\n",
        "# 2. Preprocess images\n",
        "# --------------------------\n",
        "IMG_SIZE = (224,224)\n",
        "\n",
        "def load_image(row):\n",
        "    path = row['jpg'] if pd.notna(row['jpg']) else row['dcm']\n",
        "    if path.endswith('.jpg'):\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    else:\n",
        "        dcm = pydicom.dcmread(path)\n",
        "        img = dcm.pixel_array.astype(np.float32)\n",
        "        img = np.clip(img, -100, 400)\n",
        "        img = (img - img.min()) / (img.max() - img.min()) * 255\n",
        "        img = img.astype(np.uint8)\n",
        "    img = cv2.resize(img, IMG_SIZE)\n",
        "    img = np.stack([img]*3, axis=-1)  # grayscale -> RGB\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "# تحويل DataFrame إلى numpy arrays\n",
        "images = []\n",
        "labels = []\n",
        "for _, row in df_binary.iterrows():\n",
        "    try:\n",
        "        images.append(load_image(row))\n",
        "        labels.append(row['label'])\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "X = np.array(images)\n",
        "y = np.array(labels)\n",
        "\n",
        "# --------------------------\n",
        "# 3. Train/Val/Test split\n",
        "# --------------------------\n",
        "train_X, temp_X, train_y, temp_y = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "val_X, test_X, val_y, test_y = train_test_split(temp_X, temp_y, test_size=0.5, stratify=temp_y, random_state=42)\n",
        "\n",
        "# --------------------------\n",
        "# 4. Class weights\n",
        "# --------------------------\n",
        "class_weights_values = class_weight.compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(train_y),\n",
        "    y=train_y\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights_values))\n",
        "\n",
        "# --------------------------\n",
        "# 5. Data augmentation\n",
        "# --------------------------\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8,1.2]\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator()  # no augmentation\n",
        "\n",
        "train_gen = train_datagen.flow(train_X, train_y, batch_size=8, shuffle=True)\n",
        "val_gen   = val_datagen.flow(val_X, val_y, batch_size=8, shuffle=False)\n",
        "\n",
        "# --------------------------\n",
        "# 6. Build model\n",
        "# --------------------------\n",
        "base_model = Xception(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
        "base_model.trainable = False  # freeze base model first\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# --------------------------\n",
        "# 7. Train (initial)\n",
        "# --------------------------\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr  = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
        "\n",
        "history = model.fit(train_gen,\n",
        "                    validation_data=val_gen,\n",
        "                    epochs=10,\n",
        "                    class_weight=class_weights,\n",
        "                    callbacks=[early_stop, reduce_lr])\n",
        "\n",
        "# --------------------------\n",
        "# 8. Fine-tuning\n",
        "# --------------------------\n",
        "base_model.trainable = True\n",
        "# freeze lower layers\n",
        "for layer in base_model.layers[:-50]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history_fine = model.fit(train_gen,\n",
        "                         validation_data=val_gen,\n",
        "                         epochs=10,\n",
        "                         class_weight=class_weights,\n",
        "                         callbacks=[early_stop, reduce_lr])\n",
        "\n",
        "# --------------------------\n",
        "# 9. Evaluate on test set\n",
        "# --------------------------\n",
        "test_gen = val_datagen.flow(test_X, test_y, batch_size=8, shuffle=False)\n",
        "test_loss, test_acc = model.evaluate(test_gen)\n",
        "print(\"Test Accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "TBMumac6Tryg",
        "outputId": "1c060b93-ee62-41aa-e403-225c07da9f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ xception (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m20,861,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │         \u001b[38;5;34m8,192\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m2,049\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ xception (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,871,721\u001b[0m (79.62 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,871,721</span> (79.62 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,145\u001b[0m (24.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,145</span> (24.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,865,576\u001b[0m (79.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,865,576</span> (79.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.5305 - loss: 0.8428 - val_accuracy: 0.3600 - val_loss: 0.7801 - learning_rate: 1.0000e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - accuracy: 0.6579 - loss: 0.6885 - val_accuracy: 0.5200 - val_loss: 0.8112 - learning_rate: 1.0000e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.5840 - loss: 0.6708 - val_accuracy: 0.5200 - val_loss: 0.8536 - learning_rate: 1.0000e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.5777 - loss: 0.6444 - val_accuracy: 0.5200 - val_loss: 0.8956 - learning_rate: 1.0000e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.7590 - loss: 0.5029 - val_accuracy: 0.5200 - val_loss: 0.9322 - learning_rate: 5.0000e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.6339 - loss: 0.5598 - val_accuracy: 0.5200 - val_loss: 0.9705 - learning_rate: 5.0000e-05\n",
            "Epoch 1/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.5851 - loss: 0.7960 - val_accuracy: 0.3600 - val_loss: 0.8054 - learning_rate: 1.0000e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 0.7226 - loss: 0.5807 - val_accuracy: 0.4000 - val_loss: 0.8365 - learning_rate: 1.0000e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.6785 - loss: 0.8292 - val_accuracy: 0.4400 - val_loss: 0.8646 - learning_rate: 1.0000e-05\n",
            "Epoch 4/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.7326 - loss: 0.5836 - val_accuracy: 0.4800 - val_loss: 0.9000 - learning_rate: 1.0000e-05\n",
            "Epoch 5/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.7039 - loss: 0.5751 - val_accuracy: 0.4800 - val_loss: 0.9384 - learning_rate: 5.0000e-06\n",
            "Epoch 6/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7863 - loss: 0.4204 - val_accuracy: 0.4800 - val_loss: 0.9710 - learning_rate: 5.0000e-06\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3975 - loss: 0.7765\n",
            "Test Accuracy: 0.4000000059604645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# 0. Install dependencies\n",
        "# --------------------------\n",
        "!pip install albumentations --quiet\n",
        "\n",
        "# --------------------------\n",
        "# 1. Imports\n",
        "# --------------------------\n",
        "import os\n",
        "import cv2\n",
        "import pydicom\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import albumentations as A\n",
        "\n",
        "# --------------------------\n",
        "# 2. Load dataset\n",
        "# --------------------------\n",
        "CSV_PATH = \"/content/ct_brain.csv\"\n",
        "BASE_PATH = \"/content/files\"\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# Fix paths\n",
        "df['jpg'] = df['jpg'].apply(lambda x: os.path.join(BASE_PATH, x.strip('/')) if pd.notna(x) else np.nan)\n",
        "df['dcm'] = df['dcm'].apply(lambda x: os.path.join(BASE_PATH, x.strip('/')) if pd.notna(x) else np.nan)\n",
        "\n",
        "# Keep only aneurysm vs tumor\n",
        "df_binary = df[df['type'].isin(['aneurysm', 'tumor'])].copy()\n",
        "df_binary['label'] = (df_binary['type'] == 'aneurysm').astype(int)\n",
        "\n",
        "# --------------------------\n",
        "# 3. Image preprocessing\n",
        "# --------------------------\n",
        "IMG_SIZE = 224\n",
        "\n",
        "def load_image(row):\n",
        "    path = row['jpg'] if pd.notna(row['jpg']) else row['dcm']\n",
        "    if path.endswith('.jpg'):\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    else:\n",
        "        dcm = pydicom.dcmread(path)\n",
        "        img = dcm.pixel_array.astype(np.float32)\n",
        "        img = np.clip(img, -100, 400)\n",
        "        img = (img - img.min()) / (img.max() - img.min()) * 255\n",
        "        img = img.astype(np.uint8)\n",
        "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "    img = np.stack([img]*3, axis=-1)  # grayscale -> RGB\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "images, labels = [], []\n",
        "for _, row in df_binary.iterrows():\n",
        "    try:\n",
        "        images.append(load_image(row))\n",
        "        labels.append(row['label'])\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "X = np.array(images)\n",
        "y = np.array(labels)\n",
        "\n",
        "# --------------------------\n",
        "# 4. Train/Validation/Test Split\n",
        "# --------------------------\n",
        "train_X, temp_X, train_y, temp_y = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "val_X, test_X, val_y, test_y = train_test_split(temp_X, temp_y, test_size=0.5, stratify=temp_y, random_state=42)\n",
        "\n",
        "# --------------------------\n",
        "# 5. Class weights\n",
        "# --------------------------\n",
        "class_weights_values = class_weight.compute_class_weight('balanced', classes=np.unique(train_y), y=train_y)\n",
        "class_weights = dict(enumerate(class_weights_values))\n",
        "\n",
        "# --------------------------\n",
        "# 6. Albumentations augmentation\n",
        "# --------------------------\n",
        "train_transform = A.Compose([\n",
        "    A.Rotate(limit=15),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.15, rotate_limit=0, p=0.5),\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "    A.GaussNoise(var_limit=(5.0, 20.0), p=0.3),\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([])  # no augmentation for validation/test\n",
        "\n",
        "def augment_images(X, y, transform):\n",
        "    augmented_images = []\n",
        "    augmented_labels = []\n",
        "    for img, label in zip(X, y):\n",
        "        augmented = transform(image=(img*255).astype(np.uint8))['image']\n",
        "        augmented = augmented / 255.0\n",
        "        augmented_images.append(augmented)\n",
        "        augmented_labels.append(label)\n",
        "    return np.array(augmented_images), np.array(augmented_labels)\n",
        "\n",
        "train_X_aug, train_y_aug = augment_images(train_X, train_y, train_transform)\n",
        "val_X_aug, val_y_aug = augment_images(val_X, val_y, val_transform)\n",
        "test_X_aug, test_y_aug = augment_images(test_X, test_y, val_transform)\n",
        "\n",
        "# --------------------------\n",
        "# 7. Build Xception model\n",
        "# --------------------------\n",
        "base_model = Xception(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# --------------------------\n",
        "# 8. Callbacks\n",
        "# --------------------------\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr  = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
        "\n",
        "# --------------------------\n",
        "# 9. Train (initial)\n",
        "# --------------------------\n",
        "history = model.fit(\n",
        "    train_X_aug, train_y_aug,\n",
        "    validation_data=(val_X_aug, val_y_aug),\n",
        "    epochs=15,\n",
        "    batch_size=8,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stop, reduce_lr]\n",
        ")\n",
        "\n",
        "# --------------------------\n",
        "# 10. Fine-tuning\n",
        "# --------------------------\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-50]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history_fine = model.fit(\n",
        "    train_X_aug, train_y_aug,\n",
        "    validation_data=(val_X_aug, val_y_aug),\n",
        "    epochs=15,\n",
        "    batch_size=8,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stop, reduce_lr]\n",
        ")\n",
        "\n",
        "# --------------------------\n",
        "# 11. Evaluate on test set\n",
        "# --------------------------\n",
        "test_loss, test_acc = model.evaluate(test_X_aug, test_y_aug, batch_size=8)\n",
        "print(\"Test Accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "id": "rcrTMHdOT9QJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6adec9f9-db5d-4106-814b-f1cae74751b5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "/tmp/ipython-input-3386043308.py:89: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
            "  A.GaussNoise(var_limit=(5.0, 20.0), p=0.3),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ xception (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m20,861,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │         \u001b[38;5;34m8,192\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m2,049\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ xception (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,871,721\u001b[0m (79.62 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,871,721</span> (79.62 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,145\u001b[0m (24.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,145</span> (24.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,865,576\u001b[0m (79.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,865,576</span> (79.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 0.3715 - loss: 1.1752 - val_accuracy: 0.5200 - val_loss: 0.7328 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.4270 - loss: 1.0417 - val_accuracy: 0.4800 - val_loss: 0.6996 - learning_rate: 1.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.5191 - loss: 0.9901 - val_accuracy: 0.6000 - val_loss: 0.6680 - learning_rate: 1.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.6256 - loss: 0.6607 - val_accuracy: 0.6400 - val_loss: 0.6419 - learning_rate: 1.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.6188 - loss: 0.7205 - val_accuracy: 0.6400 - val_loss: 0.6097 - learning_rate: 1.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.6061 - loss: 0.7296 - val_accuracy: 0.6800 - val_loss: 0.5804 - learning_rate: 1.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.6450 - loss: 0.7433 - val_accuracy: 0.8400 - val_loss: 0.5507 - learning_rate: 1.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.6419 - loss: 0.6396 - val_accuracy: 0.8400 - val_loss: 0.5247 - learning_rate: 1.0000e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.7130 - loss: 0.5728 - val_accuracy: 0.8800 - val_loss: 0.4950 - learning_rate: 1.0000e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.6620 - loss: 0.5921 - val_accuracy: 0.8800 - val_loss: 0.4678 - learning_rate: 1.0000e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.6915 - loss: 0.5722 - val_accuracy: 0.8800 - val_loss: 0.4407 - learning_rate: 1.0000e-04\n",
            "Epoch 12/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.7997 - loss: 0.4726 - val_accuracy: 0.8800 - val_loss: 0.4164 - learning_rate: 1.0000e-04\n",
            "Epoch 13/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.7807 - loss: 0.4451 - val_accuracy: 0.8800 - val_loss: 0.3948 - learning_rate: 1.0000e-04\n",
            "Epoch 14/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.7634 - loss: 0.4858 - val_accuracy: 0.8800 - val_loss: 0.3714 - learning_rate: 1.0000e-04\n",
            "Epoch 15/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.7290 - loss: 0.5085 - val_accuracy: 0.9200 - val_loss: 0.3514 - learning_rate: 1.0000e-04\n",
            "Epoch 1/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.8178 - loss: 0.3904 - val_accuracy: 0.9200 - val_loss: 0.2671 - learning_rate: 1.0000e-05\n",
            "Epoch 2/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.8395 - loss: 0.4688 - val_accuracy: 0.9200 - val_loss: 0.2019 - learning_rate: 1.0000e-05\n",
            "Epoch 3/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8164 - loss: 0.4181 - val_accuracy: 0.9600 - val_loss: 0.1628 - learning_rate: 1.0000e-05\n",
            "Epoch 4/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9174 - loss: 0.2214 - val_accuracy: 0.9600 - val_loss: 0.1376 - learning_rate: 1.0000e-05\n",
            "Epoch 5/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8832 - loss: 0.3040 - val_accuracy: 0.9600 - val_loss: 0.1189 - learning_rate: 1.0000e-05\n",
            "Epoch 6/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9293 - loss: 0.1926 - val_accuracy: 0.9600 - val_loss: 0.1092 - learning_rate: 1.0000e-05\n",
            "Epoch 7/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9582 - loss: 0.1177 - val_accuracy: 0.9600 - val_loss: 0.1002 - learning_rate: 1.0000e-05\n",
            "Epoch 8/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9535 - loss: 0.2123 - val_accuracy: 0.9600 - val_loss: 0.0917 - learning_rate: 1.0000e-05\n",
            "Epoch 9/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9925 - loss: 0.0758 - val_accuracy: 0.9600 - val_loss: 0.0848 - learning_rate: 1.0000e-05\n",
            "Epoch 10/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9761 - loss: 0.0924 - val_accuracy: 0.9600 - val_loss: 0.0743 - learning_rate: 1.0000e-05\n",
            "Epoch 11/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9563 - loss: 0.0883 - val_accuracy: 0.9600 - val_loss: 0.0597 - learning_rate: 1.0000e-05\n",
            "Epoch 12/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9876 - loss: 0.0422 - val_accuracy: 1.0000 - val_loss: 0.0500 - learning_rate: 1.0000e-05\n",
            "Epoch 13/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9850 - loss: 0.0748 - val_accuracy: 1.0000 - val_loss: 0.0440 - learning_rate: 1.0000e-05\n",
            "Epoch 14/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9757 - loss: 0.0611 - val_accuracy: 1.0000 - val_loss: 0.0379 - learning_rate: 1.0000e-05\n",
            "Epoch 15/15\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9525 - loss: 0.0859 - val_accuracy: 1.0000 - val_loss: 0.0329 - learning_rate: 1.0000e-05\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0480\n",
            "Test Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import pydicom\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.applications import Xception\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "import albumentations as A\n",
        "\n",
        "# --------------------------\n",
        "# 1. Load & filter dataset\n",
        "# --------------------------\n",
        "CSV_PATH = \"/content/ct_brain.csv\"\n",
        "BASE_PATH = \"/content/files\"\n",
        "\n",
        "df_exp2 = pd.read_csv(CSV_PATH)\n",
        "df_exp2['jpg'] = df_exp2['jpg'].apply(lambda x: os.path.join(BASE_PATH, x.strip('/')) if pd.notna(x) else np.nan)\n",
        "df_exp2['dcm'] = df_exp2['dcm'].apply(lambda x: os.path.join(BASE_PATH, x.strip('/')) if pd.notna(x) else np.nan)\n",
        "\n",
        "# Keep only 'aneurysm' and 'tumor'\n",
        "df_exp2 = df_exp2[df_exp2['type'].isin(['aneurysm', 'tumor'])].copy()\n",
        "df_exp2['label'] = (df_exp2['type'] == 'aneurysm').astype(int)\n",
        "\n",
        "# --------------------------\n",
        "# 2. Preprocessing & Augmentation\n",
        "# --------------------------\n",
        "IMG_SIZE = 224\n",
        "\n",
        "# Albumentations pipeline\n",
        "aug_exp2 = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.2),\n",
        "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.15, rotate_limit=20, p=0.7),\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.7),\n",
        "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
        "])\n",
        "\n",
        "def load_preprocess_exp2(row, augment=True):\n",
        "    path = row['jpg'] if pd.notna(row['jpg']) else row['dcm']\n",
        "    if path.endswith('.jpg'):\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    else:\n",
        "        dcm = pydicom.dcmread(path)\n",
        "        img = dcm.pixel_array.astype(np.float32)\n",
        "        img = np.clip(img, -100, 400)\n",
        "        img = (img - img.min()) / (img.max() - img.min()) * 255\n",
        "        img = img.astype(np.uint8)\n",
        "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "    img = np.stack([img]*3, axis=-1)  # grayscale -> RGB\n",
        "    img = img / 255.0\n",
        "    if augment:\n",
        "        img = aug_exp2(image=img)['image']\n",
        "    return img\n",
        "\n",
        "# Convert DataFrame to numpy arrays\n",
        "images_exp2, labels_exp2 = [], []\n",
        "for _, row in df_exp2.iterrows():\n",
        "    try:\n",
        "        images_exp2.append(load_preprocess_exp2(row))\n",
        "        labels_exp2.append(row['label'])\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "X_exp2 = np.array(images_exp2)\n",
        "y_exp2 = np.array(labels_exp2)\n",
        "\n",
        "# --------------------------\n",
        "# 3. Train/Val/Test split\n",
        "# --------------------------\n",
        "X_train2, X_temp2, y_train2, y_temp2 = train_test_split(X_exp2, y_exp2, test_size=0.3, stratify=y_exp2, random_state=42)\n",
        "X_val2, X_test2, y_val2, y_test2 = train_test_split(X_temp2, y_temp2, test_size=0.5, stratify=y_temp2, random_state=42)\n",
        "\n",
        "# --------------------------\n",
        "# 4. Class weights\n",
        "# --------------------------\n",
        "class_weights_values2 = class_weight.compute_class_weight('balanced', classes=np.unique(y_train2), y=y_train2)\n",
        "class_weights2 = dict(enumerate(class_weights_values2))\n",
        "\n",
        "# --------------------------\n",
        "# 5. Keras ImageDataGenerator\n",
        "# --------------------------\n",
        "train_datagen2 = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "val_datagen2   = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "train_gen2 = train_datagen2.flow(X_train2, y_train2, batch_size=8, shuffle=True)\n",
        "val_gen2   = val_datagen2.flow(X_val2, y_val2, batch_size=8, shuffle=False)\n",
        "\n",
        "# --------------------------\n",
        "# 6. Build Xception model\n",
        "# --------------------------\n",
        "base_model2 = Xception(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "base_model2.trainable = False  # freeze all first\n",
        "\n",
        "model_exp2 = models.Sequential([\n",
        "    base_model2,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.6),\n",
        "    layers.Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(1e-4))\n",
        "])\n",
        "\n",
        "model_exp2.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "                   loss='binary_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "model_exp2.summary()\n",
        "\n",
        "# --------------------------\n",
        "# 7. Train initial model\n",
        "# --------------------------\n",
        "early_stop2 = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr2  = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
        "\n",
        "history_exp2 = model_exp2.fit(train_gen2,\n",
        "                              validation_data=val_gen2,\n",
        "                              epochs=10,\n",
        "                              class_weight=class_weights2,\n",
        "                              callbacks=[early_stop2, reduce_lr2])\n",
        "\n",
        "# --------------------------\n",
        "# 8. Fine-tuning top layers\n",
        "# --------------------------\n",
        "base_model2.trainable = True\n",
        "# freeze lower layers, only fine-tune top 50 layers\n",
        "for layer in base_model2.layers[:-50]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model_exp2.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "                   loss='binary_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "history_ft2 = model_exp2.fit(train_gen2,\n",
        "                             validation_data=val_gen2,\n",
        "                             epochs=10,\n",
        "                             class_weight=class_weights2,\n",
        "                             callbacks=[early_stop2, reduce_lr2])\n",
        "\n",
        "# --------------------------\n",
        "# 9. Evaluate on test set\n",
        "# --------------------------\n",
        "test_gen2 = val_datagen2.flow(X_test2, y_test2, batch_size=8, shuffle=False)\n",
        "test_loss2, test_acc2 = model_exp2.evaluate(test_gen2)\n",
        "print(\"Test Accuracy (Experiment 2):\", test_acc2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YLS5LKHlgd-a",
        "outputId": "59b19003-65cb-4f05-b889-fabf325df271"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "/tmp/ipython-input-1264819608.py:38: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
            "  A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ xception (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m20,861,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │         \u001b[38;5;34m8,192\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m2,049\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ xception (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,871,721\u001b[0m (79.62 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,871,721</span> (79.62 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,145\u001b[0m (24.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,145</span> (24.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,865,576\u001b[0m (79.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,865,576</span> (79.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3s/step - accuracy: 0.5456 - loss: 1.0153 - val_accuracy: 0.4211 - val_loss: 0.7011 - learning_rate: 1.0000e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.6021 - loss: 0.8264 - val_accuracy: 0.4211 - val_loss: 0.6697 - learning_rate: 1.0000e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.6277 - loss: 0.9172 - val_accuracy: 0.5263 - val_loss: 0.6351 - learning_rate: 1.0000e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.7048 - loss: 0.5778 - val_accuracy: 0.6316 - val_loss: 0.5991 - learning_rate: 1.0000e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.6606 - loss: 0.7228 - val_accuracy: 0.7368 - val_loss: 0.5641 - learning_rate: 1.0000e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7149 - loss: 0.5965 - val_accuracy: 0.7895 - val_loss: 0.5319 - learning_rate: 1.0000e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7917 - loss: 0.4695 - val_accuracy: 0.7895 - val_loss: 0.5029 - learning_rate: 1.0000e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7976 - loss: 0.5862 - val_accuracy: 0.7895 - val_loss: 0.4736 - learning_rate: 1.0000e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7708 - loss: 0.5874 - val_accuracy: 0.8421 - val_loss: 0.4470 - learning_rate: 1.0000e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8549 - loss: 0.3269 - val_accuracy: 0.8947 - val_loss: 0.4217 - learning_rate: 1.0000e-04\n",
            "Epoch 1/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.6299 - loss: 0.8744 - val_accuracy: 0.9474 - val_loss: 0.3776 - learning_rate: 1.0000e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7980 - loss: 0.5653 - val_accuracy: 0.9474 - val_loss: 0.3385 - learning_rate: 1.0000e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8668 - loss: 0.3038 - val_accuracy: 0.9474 - val_loss: 0.2938 - learning_rate: 1.0000e-05\n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.7568 - loss: 0.4318 - val_accuracy: 0.9474 - val_loss: 0.2531 - learning_rate: 1.0000e-05\n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.7705 - loss: 0.5443 - val_accuracy: 0.9474 - val_loss: 0.2227 - learning_rate: 1.0000e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9509 - loss: 0.1465 - val_accuracy: 0.9474 - val_loss: 0.1975 - learning_rate: 1.0000e-05\n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8988 - loss: 0.3006 - val_accuracy: 0.9474 - val_loss: 0.1747 - learning_rate: 1.0000e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9039 - loss: 0.2383 - val_accuracy: 0.9474 - val_loss: 0.1555 - learning_rate: 1.0000e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9581 - loss: 0.1123 - val_accuracy: 0.9474 - val_loss: 0.1400 - learning_rate: 1.0000e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9788 - loss: 0.0577 - val_accuracy: 0.9474 - val_loss: 0.1236 - learning_rate: 1.0000e-05\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.1018\n",
            "Test Accuracy (Experiment 2): 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# Third Experiment: No Class Weights\n",
        "# --------------------------\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import pydicom\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --------------------------\n",
        "# 1. Load dataset\n",
        "# --------------------------\n",
        "CSV_PATH = \"/content/ct_brain.csv\"\n",
        "BASE_PATH = \"/content/files\"\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# Fix paths\n",
        "df['jpg'] = df['jpg'].apply(lambda x: os.path.join(BASE_PATH, x.strip('/')) if pd.notna(x) else np.nan)\n",
        "df['dcm'] = df['dcm'].apply(lambda x: os.path.join(BASE_PATH, x.strip('/')) if pd.notna(x) else np.nan)\n",
        "\n",
        "# Select only aneurysm vs tumor\n",
        "df_binary = df[df['type'].isin(['aneurysm', 'tumor'])].copy()\n",
        "df_binary['label'] = (df_binary['type'] == 'aneurysm').astype(int)\n",
        "\n",
        "# --------------------------\n",
        "# 2. Preprocess images\n",
        "# --------------------------\n",
        "IMG_SIZE = (224,224)\n",
        "\n",
        "def load_image(row):\n",
        "    path = row['jpg'] if pd.notna(row['jpg']) else row['dcm']\n",
        "    if path.endswith('.jpg'):\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    else:\n",
        "        dcm = pydicom.dcmread(path)\n",
        "        img = dcm.pixel_array.astype(np.float32)\n",
        "        img = np.clip(img, -100, 400)\n",
        "        img = (img - img.min()) / (img.max() - img.min()) * 255\n",
        "        img = img.astype(np.uint8)\n",
        "    img = cv2.resize(img, IMG_SIZE)\n",
        "    img = np.stack([img]*3, axis=-1)  # grayscale -> RGB\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "images, labels = [], []\n",
        "for _, row in df_binary.iterrows():\n",
        "    try:\n",
        "        images.append(load_image(row))\n",
        "        labels.append(row['label'])\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "X = np.array(images)\n",
        "y = np.array(labels)\n",
        "\n",
        "# --------------------------\n",
        "# 3. Train/Val/Test split\n",
        "# --------------------------\n",
        "train_X, temp_X, train_y, temp_y = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "val_X, test_X, val_y, test_y = train_test_split(temp_X, temp_y, test_size=0.5, stratify=temp_y, random_state=42)\n",
        "\n",
        "# --------------------------\n",
        "# 4. Data augmentation\n",
        "# --------------------------\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    zoom_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.7,1.3]\n",
        ")\n",
        "val_datagen = ImageDataGenerator()  # no augmentation for validation/test\n",
        "\n",
        "train_gen = train_datagen.flow(train_X, train_y, batch_size=8, shuffle=True)\n",
        "val_gen   = val_datagen.flow(val_X, val_y, batch_size=8, shuffle=False)\n",
        "\n",
        "# --------------------------\n",
        "# 5. Build Xception model\n",
        "# --------------------------\n",
        "base_model = Xception(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
        "base_model.trainable = False  # freeze base first\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# --------------------------\n",
        "# 6. Train initial layers\n",
        "# --------------------------\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr  = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
        "\n",
        "history = model.fit(train_gen,\n",
        "                    validation_data=val_gen,\n",
        "                    epochs=10)  # no class weights\n",
        "\n",
        "# --------------------------\n",
        "# 7. Fine-tuning top layers\n",
        "# --------------------------\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-50]:  # freeze lower layers\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history_fine = model.fit(train_gen,\n",
        "                         validation_data=val_gen,\n",
        "                         epochs=10)  # still no class weights\n",
        "\n",
        "# --------------------------\n",
        "# 8. Evaluate on test set\n",
        "# --------------------------\n",
        "test_gen = val_datagen.flow(test_X, test_y, batch_size=8, shuffle=False)\n",
        "test_loss, test_acc = model.evaluate(test_gen)\n",
        "print(\"Test Accuracy (Experiment 3, no class weights):\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JJQDHsImip0x",
        "outputId": "db1c3c56-2a07-41c3-d3ae-83940aa9c644"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ xception (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m20,861,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │         \u001b[38;5;34m8,192\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m2,049\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ xception (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,871,721\u001b[0m (79.62 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,871,721</span> (79.62 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,145\u001b[0m (24.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,145</span> (24.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,865,576\u001b[0m (79.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,865,576</span> (79.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 962ms/step - accuracy: 0.5145 - loss: 0.7359 - val_accuracy: 0.4400 - val_loss: 0.7390\n",
            "Epoch 2/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.6082 - loss: 0.6873 - val_accuracy: 0.4800 - val_loss: 0.7580\n",
            "Epoch 3/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 181ms/step - accuracy: 0.7438 - loss: 0.5732 - val_accuracy: 0.5200 - val_loss: 0.7874\n",
            "Epoch 4/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.6207 - loss: 0.6393 - val_accuracy: 0.5200 - val_loss: 0.8142\n",
            "Epoch 5/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.5777 - loss: 0.6755 - val_accuracy: 0.5200 - val_loss: 0.8314\n",
            "Epoch 6/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.7184 - loss: 0.5790 - val_accuracy: 0.5200 - val_loss: 0.8616\n",
            "Epoch 7/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.6075 - loss: 0.6603 - val_accuracy: 0.5200 - val_loss: 0.8881\n",
            "Epoch 8/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.7738 - loss: 0.4997 - val_accuracy: 0.5200 - val_loss: 0.9251\n",
            "Epoch 9/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - accuracy: 0.5688 - loss: 0.6234 - val_accuracy: 0.5200 - val_loss: 0.9400\n",
            "Epoch 10/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 146ms/step - accuracy: 0.7125 - loss: 0.5362 - val_accuracy: 0.5200 - val_loss: 0.9571\n",
            "Epoch 1/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.7600 - loss: 0.6110 - val_accuracy: 0.5200 - val_loss: 1.0375\n",
            "Epoch 2/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.6734 - loss: 0.7932 - val_accuracy: 0.5200 - val_loss: 1.1732\n",
            "Epoch 3/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.7301 - loss: 0.5538 - val_accuracy: 0.5200 - val_loss: 1.2457\n",
            "Epoch 4/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.8139 - loss: 0.4573 - val_accuracy: 0.5200 - val_loss: 1.3002\n",
            "Epoch 5/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.7183 - loss: 0.5516 - val_accuracy: 0.5200 - val_loss: 1.3306\n",
            "Epoch 6/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 142ms/step - accuracy: 0.6118 - loss: 0.5863 - val_accuracy: 0.5200 - val_loss: 1.3497\n",
            "Epoch 7/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7196 - loss: 0.5572 - val_accuracy: 0.5200 - val_loss: 1.3582\n",
            "Epoch 8/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.6693 - loss: 0.5875 - val_accuracy: 0.5200 - val_loss: 1.3529\n",
            "Epoch 9/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7752 - loss: 0.5279 - val_accuracy: 0.5200 - val_loss: 1.3963\n",
            "Epoch 10/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7547 - loss: 0.5606 - val_accuracy: 0.5200 - val_loss: 1.3814\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4837 - loss: 1.6723\n",
            "Test Accuracy (Experiment 3, no class weights): 0.47999998927116394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import pydicom\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "import albumentations as A\n",
        "\n",
        "# --------------------------\n",
        "# 1. Load CSV and filter dataset\n",
        "# --------------------------\n",
        "CSV_PATH = \"/content/ct_brain.csv\"\n",
        "BASE_PATH = \"/content/files\"\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# إصلاح المسارات\n",
        "df['jpg'] = df['jpg'].apply(lambda x: os.path.join(BASE_PATH, x.strip('/')) if pd.notna(x) else np.nan)\n",
        "df['dcm'] = df['dcm'].apply(lambda x: os.path.join(BASE_PATH, x.strip('/')) if pd.notna(x) else np.nan)\n",
        "\n",
        "# اختيار فئتين فقط: aneurysm vs cancer\n",
        "df_binary = df[df['type'].isin(['aneurysm', 'cancer'])].copy()\n",
        "df_binary['label'] = (df_binary['type'] == 'aneurysm').astype(int)\n",
        "print(df_binary['type'].value_counts())\n",
        "\n",
        "# --------------------------\n",
        "# 2. Preprocess images\n",
        "# --------------------------\n",
        "IMG_SIZE = (224,224)\n",
        "\n",
        "def load_image(row):\n",
        "    path = row['jpg'] if pd.notna(row['jpg']) else row['dcm']\n",
        "    if path.endswith('.jpg'):\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    else:\n",
        "        dcm = pydicom.dcmread(path)\n",
        "        img = dcm.pixel_array.astype(np.float32)\n",
        "        img = np.clip(img, -100, 400)\n",
        "        img = (img - img.min()) / (img.max() - img.min()) * 255\n",
        "        img = img.astype(np.uint8)\n",
        "    img = cv2.resize(img, IMG_SIZE)\n",
        "    img = np.stack([img]*3, axis=-1)  # grayscale -> RGB\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "for _, row in df_binary.iterrows():\n",
        "    try:\n",
        "        images.append(load_image(row))\n",
        "        labels.append(row['label'])\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "X = np.array(images)\n",
        "y = np.array(labels)\n",
        "\n",
        "# --------------------------\n",
        "# 3. Train/Val/Test split\n",
        "# --------------------------\n",
        "train_X, temp_X, train_y, temp_y = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "val_X, test_X, val_y, test_y = train_test_split(temp_X, temp_y, test_size=0.5, stratify=temp_y, random_state=42)\n",
        "\n",
        "# --------------------------\n",
        "# 4. Class weights\n",
        "# --------------------------\n",
        "class_weights_values = class_weight.compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(train_y),\n",
        "    y=train_y\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights_values))\n",
        "\n",
        "# --------------------------\n",
        "# 5. Albumentations augmentation\n",
        "# --------------------------\n",
        "train_transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3)\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([])  # no augmentation\n",
        "\n",
        "def augment_images(X, y, transform):\n",
        "    X_aug, y_aug = [], []\n",
        "    for img, label in zip(X, y):\n",
        "        augmented = transform(image=(img*255).astype(np.uint8))['image']\n",
        "        X_aug.append(augmented / 255.0)\n",
        "        y_aug.append(label)\n",
        "    return np.array(X_aug), np.array(y_aug)\n",
        "\n",
        "train_X_aug, train_y_aug = augment_images(train_X, train_y, train_transform)\n",
        "val_X_aug, val_y_aug     = augment_images(val_X, val_y, val_transform)\n",
        "\n",
        "# --------------------------\n",
        "# 6. Build Xception model\n",
        "# --------------------------\n",
        "base_model = Xception(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
        "base_model.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# --------------------------\n",
        "# 7. Train model (initial)\n",
        "# --------------------------\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr  = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
        "\n",
        "history = model.fit(\n",
        "    train_X_aug, train_y_aug,\n",
        "    validation_data=(val_X_aug, val_y_aug),\n",
        "    epochs=10,\n",
        "    batch_size=8,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stop, reduce_lr]\n",
        ")\n",
        "\n",
        "# --------------------------\n",
        "# 8. Fine-tuning\n",
        "# --------------------------\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-50]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_fine = model.fit(\n",
        "    train_X_aug, train_y_aug,\n",
        "    validation_data=(val_X_aug, val_y_aug),\n",
        "    epochs=10,\n",
        "    batch_size=8,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stop, reduce_lr]\n",
        ")\n",
        "\n",
        "# --------------------------\n",
        "# 9. Evaluate on test set\n",
        "# --------------------------\n",
        "test_loss, test_acc = model.evaluate(test_X, test_y)\n",
        "print(\"Test Accuracy (aneurysm vs cancer):\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XwXTyktEkSqu",
        "outputId": "bebf919c-8681-4d9a-d81b-9e3e6e72d674"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type\n",
            "cancer      90\n",
            "aneurysm    83\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "/tmp/ipython-input-315530026.py:86: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
            "  A.GaussNoise(var_limit=(10.0, 50.0), p=0.3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ xception (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m20,861,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_3      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │         \u001b[38;5;34m8,192\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m2,049\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ xception (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_3      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,871,721\u001b[0m (79.62 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,871,721</span> (79.62 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,145\u001b[0m (24.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,145</span> (24.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,865,576\u001b[0m (79.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,865,576</span> (79.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 0.5535 - loss: 0.8628 - val_accuracy: 0.6154 - val_loss: 0.6332 - learning_rate: 1.0000e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.5970 - loss: 0.8525 - val_accuracy: 0.6154 - val_loss: 0.6142 - learning_rate: 1.0000e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.5643 - loss: 0.8407 - val_accuracy: 0.6154 - val_loss: 0.5943 - learning_rate: 1.0000e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.6266 - loss: 0.6880 - val_accuracy: 0.6154 - val_loss: 0.5719 - learning_rate: 1.0000e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.6564 - loss: 0.7704 - val_accuracy: 0.6538 - val_loss: 0.5501 - learning_rate: 1.0000e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.6770 - loss: 0.6539 - val_accuracy: 0.6538 - val_loss: 0.5311 - learning_rate: 1.0000e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.6486 - loss: 0.6822 - val_accuracy: 0.7308 - val_loss: 0.5095 - learning_rate: 1.0000e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.6973 - loss: 0.6383 - val_accuracy: 0.7692 - val_loss: 0.4869 - learning_rate: 1.0000e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7226 - loss: 0.5075 - val_accuracy: 0.7692 - val_loss: 0.4644 - learning_rate: 1.0000e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.6688 - loss: 0.6132 - val_accuracy: 0.8077 - val_loss: 0.4419 - learning_rate: 1.0000e-04\n",
            "Epoch 1/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.7004 - loss: 0.6769 - val_accuracy: 0.8846 - val_loss: 0.3956 - learning_rate: 1.0000e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.6935 - loss: 0.5409 - val_accuracy: 0.8846 - val_loss: 0.3601 - learning_rate: 1.0000e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8486 - loss: 0.3281 - val_accuracy: 0.9231 - val_loss: 0.3278 - learning_rate: 1.0000e-05\n",
            "Epoch 4/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7760 - loss: 0.4210 - val_accuracy: 0.9231 - val_loss: 0.2852 - learning_rate: 1.0000e-05\n",
            "Epoch 5/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8792 - loss: 0.3199 - val_accuracy: 0.9231 - val_loss: 0.2583 - learning_rate: 1.0000e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9285 - loss: 0.1858 - val_accuracy: 0.9231 - val_loss: 0.2253 - learning_rate: 1.0000e-05\n",
            "Epoch 7/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.8452 - loss: 0.3271 - val_accuracy: 0.9231 - val_loss: 0.1942 - learning_rate: 1.0000e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9578 - loss: 0.1446 - val_accuracy: 0.9231 - val_loss: 0.1746 - learning_rate: 1.0000e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9379 - loss: 0.1615 - val_accuracy: 0.9231 - val_loss: 0.1591 - learning_rate: 1.0000e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9294 - loss: 0.1950 - val_accuracy: 0.9231 - val_loss: 0.1383 - learning_rate: 1.0000e-05\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 0.8846 - loss: 0.1659\n",
            "Test Accuracy (aneurysm vs cancer): 0.8846153616905212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import pydicom\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import Xception\n",
        "from sklearn.model_selection import train_test_split\n",
        "import albumentations as A\n",
        "\n",
        "# --------------------------\n",
        "# 1. Load dataset\n",
        "# --------------------------\n",
        "CSV_PATH = \"/content/ct_brain.csv\"\n",
        "BASE_PATH = \"/content/files\"\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "df['jpg'] = df['jpg'].apply(lambda x: os.path.join(BASE_PATH, x.strip('/')) if pd.notna(x) else np.nan)\n",
        "df['dcm'] = df['dcm'].apply(lambda x: os.path.join(BASE_PATH, x.strip('/')) if pd.notna(x) else np.nan)\n",
        "\n",
        "# Keep only aneurysm and cancer\n",
        "df_binary = df[df['type'].isin(['aneurysm','cancer'])].copy()\n",
        "df_binary['label'] = (df_binary['type']=='aneurysm').astype(int)\n",
        "\n",
        "# --------------------------\n",
        "# 2. Preprocessing\n",
        "# --------------------------\n",
        "IMG_SIZE = (224,224)\n",
        "\n",
        "def load_image(row):\n",
        "    path = row['jpg'] if pd.notna(row['jpg']) else row['dcm']\n",
        "    if path.endswith('.jpg'):\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    else:\n",
        "        dcm = pydicom.dcmread(path)\n",
        "        img = dcm.pixel_array.astype(np.float32)\n",
        "        img = np.clip(img, -100, 400)\n",
        "        img = (img - img.min()) / (img.max() - img.min()) * 255\n",
        "        img = img.astype(np.uint8)\n",
        "    img = cv2.resize(img, IMG_SIZE)\n",
        "    img = np.stack([img]*3, axis=-1)  # grayscale -> RGB\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "images, labels = [], []\n",
        "for _, row in df_binary.iterrows():\n",
        "    try:\n",
        "        images.append(load_image(row))\n",
        "        labels.append(row['label'])\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "X = np.array(images)\n",
        "y = np.array(labels)\n",
        "\n",
        "# --------------------------\n",
        "# 3. Train/Val/Test split\n",
        "# --------------------------\n",
        "train_X, temp_X, train_y, temp_y = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "val_X, test_X, val_y, test_y = train_test_split(temp_X, temp_y, test_size=0.5, stratify=temp_y, random_state=42)\n",
        "\n",
        "# --------------------------\n",
        "# 4. Augmentation (fixed)\n",
        "# --------------------------\n",
        "train_aug = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.3),\n",
        "    A.Rotate(limit=30, p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.Affine(translate_percent=0.1, scale=(0.9,1.1), rotate=(-15,15), p=0.5),\n",
        "    A.ElasticTransform(alpha=1, sigma=50, p=0.3),\n",
        "    A.GaussNoise(var_limit=(10,50), p=0.3)\n",
        "])\n",
        "\n",
        "val_aug = A.Compose([])\n",
        "\n",
        "def augment_images(X, y, aug):\n",
        "    X_aug, y_aug = [], []\n",
        "    for img, label in zip(X, y):\n",
        "        # Convert to uint8 for Albumentations\n",
        "        img_uint8 = (img * 255).astype(np.uint8)\n",
        "        augmented = aug(image=img_uint8)['image']\n",
        "        # Convert back to float [0,1] after augmentation\n",
        "        X_aug.append(augmented.astype(np.float32)/255.0)\n",
        "        y_aug.append(label)\n",
        "    return np.array(X_aug), np.array(y_aug)\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 5. Build model\n",
        "# --------------------------\n",
        "base_model = Xception(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
        "base_model.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# --------------------------\n",
        "# 6. Train (initial)\n",
        "# --------------------------\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr  = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
        "\n",
        "history = model.fit(train_X_aug, train_y_aug,\n",
        "                    validation_data=(val_X_aug, val_y_aug),\n",
        "                    epochs=15,\n",
        "                    batch_size=8,\n",
        "                    callbacks=[early_stop, reduce_lr])\n",
        "\n",
        "# --------------------------\n",
        "# 7. Fine-tuning\n",
        "# --------------------------\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-50]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history_fine = model.fit(train_X_aug, train_y_aug,\n",
        "                         validation_data=(val_X_aug, val_y_aug),\n",
        "                         epochs=10,\n",
        "                         batch_size=8,\n",
        "                         callbacks=[early_stop, reduce_lr])\n",
        "\n",
        "# --------------------------\n",
        "# 8. Evaluate\n",
        "# --------------------------\n",
        "test_loss, test_acc = model.evaluate(test_X, test_y, batch_size=8)\n",
        "print(\"Test Accuracy (Experiment 4, no class weights, strong augmentation):\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYUk7K0nlHXG",
        "outputId": "9dc282a6-1c6c-4ebd-cca4-a9c89f577482"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2942592840.py:73: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
            "  A.GaussNoise(var_limit=(10,50), p=0.3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 866ms/step - accuracy: 0.4327 - loss: 1.0712 - val_accuracy: 0.3462 - val_loss: 0.7726 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.5067 - loss: 0.9510 - val_accuracy: 0.3462 - val_loss: 0.7575 - learning_rate: 1.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.6249 - loss: 0.7648 - val_accuracy: 0.4231 - val_loss: 0.7440 - learning_rate: 1.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.6054 - loss: 0.8088 - val_accuracy: 0.5000 - val_loss: 0.7298 - learning_rate: 1.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.6180 - loss: 0.7550 - val_accuracy: 0.5000 - val_loss: 0.7159 - learning_rate: 1.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.6307 - loss: 0.7669 - val_accuracy: 0.5000 - val_loss: 0.6997 - learning_rate: 1.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.7353 - loss: 0.6039 - val_accuracy: 0.5000 - val_loss: 0.6848 - learning_rate: 1.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7593 - loss: 0.4833 - val_accuracy: 0.5385 - val_loss: 0.6694 - learning_rate: 1.0000e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.6426 - loss: 0.6499 - val_accuracy: 0.6154 - val_loss: 0.6505 - learning_rate: 1.0000e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.6752 - loss: 0.6077 - val_accuracy: 0.6154 - val_loss: 0.6286 - learning_rate: 1.0000e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7465 - loss: 0.5267 - val_accuracy: 0.6154 - val_loss: 0.6061 - learning_rate: 1.0000e-04\n",
            "Epoch 12/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7006 - loss: 0.5808 - val_accuracy: 0.6538 - val_loss: 0.5823 - learning_rate: 1.0000e-04\n",
            "Epoch 13/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7790 - loss: 0.4330 - val_accuracy: 0.6923 - val_loss: 0.5616 - learning_rate: 1.0000e-04\n",
            "Epoch 14/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7349 - loss: 0.4817 - val_accuracy: 0.7692 - val_loss: 0.5374 - learning_rate: 1.0000e-04\n",
            "Epoch 15/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8178 - loss: 0.4472 - val_accuracy: 0.7692 - val_loss: 0.5162 - learning_rate: 1.0000e-04\n",
            "Epoch 1/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.6490 - loss: 0.6862 - val_accuracy: 0.8462 - val_loss: 0.4322 - learning_rate: 1.0000e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.7901 - loss: 0.4067 - val_accuracy: 0.9231 - val_loss: 0.3619 - learning_rate: 1.0000e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.8521 - loss: 0.3464 - val_accuracy: 0.8846 - val_loss: 0.2930 - learning_rate: 1.0000e-05\n",
            "Epoch 4/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.8755 - loss: 0.3055 - val_accuracy: 0.8846 - val_loss: 0.2501 - learning_rate: 1.0000e-05\n",
            "Epoch 5/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9040 - loss: 0.2423 - val_accuracy: 0.8846 - val_loss: 0.2158 - learning_rate: 1.0000e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9383 - loss: 0.1549 - val_accuracy: 0.8846 - val_loss: 0.1866 - learning_rate: 1.0000e-05\n",
            "Epoch 7/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9588 - loss: 0.1678 - val_accuracy: 0.9231 - val_loss: 0.1653 - learning_rate: 1.0000e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9702 - loss: 0.1250 - val_accuracy: 0.9615 - val_loss: 0.1306 - learning_rate: 1.0000e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9087 - loss: 0.1700 - val_accuracy: 0.9615 - val_loss: 0.1199 - learning_rate: 1.0000e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9805 - loss: 0.0940 - val_accuracy: 0.9615 - val_loss: 0.1182 - learning_rate: 1.0000e-05\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9163 - loss: 0.1951\n",
            "Test Accuracy (Experiment 4, no class weights, strong augmentation): 0.8846153616905212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import pydicom\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import Xception\n",
        "from sklearn.model_selection import train_test_split\n",
        "import albumentations as A\n",
        "\n",
        "# --------------------------\n",
        "# 1. Load dataset\n",
        "# --------------------------\n",
        "CSV_PATH = \"/content/ct_brain.csv\"\n",
        "BASE_PATH = \"/content/files\"\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "df['jpg'] = df['jpg'].apply(lambda x: os.path.join(BASE_PATH, x.strip('/')) if pd.notna(x) else np.nan)\n",
        "df['dcm'] = df['dcm'].apply(lambda x: os.path.join(BASE_PATH, x.strip('/')) if pd.notna(x) else np.nan)\n",
        "\n",
        "# Keep only aneurysm and cancer\n",
        "df_binary = df[df['type'].isin(['aneurysm','cancer'])].copy()\n",
        "df_binary['label'] = (df_binary['type']=='aneurysm').astype(int)\n",
        "\n",
        "# --------------------------\n",
        "# 2. Preprocessing function\n",
        "# --------------------------\n",
        "IMG_SIZE = (224,224)\n",
        "\n",
        "def load_image(row):\n",
        "    path = row['jpg'] if pd.notna(row['jpg']) else row['dcm']\n",
        "    if path.endswith('.jpg'):\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    else:\n",
        "        dcm = pydicom.dcmread(path)\n",
        "        img = dcm.pixel_array.astype(np.float32)\n",
        "        img = np.clip(img, -100, 400)\n",
        "        img = (img - img.min()) / (img.max() - img.min()) * 255\n",
        "        img = img.astype(np.uint8)\n",
        "    img = cv2.resize(img, IMG_SIZE)\n",
        "    img = np.stack([img]*3, axis=-1)  # grayscale -> RGB\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "images, labels = [], []\n",
        "for _, row in df_binary.iterrows():\n",
        "    try:\n",
        "        images.append(load_image(row))\n",
        "        labels.append(row['label'])\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "X = np.array(images)\n",
        "y = np.array(labels)\n",
        "\n",
        "# --------------------------\n",
        "# 3. Train/Val/Test split\n",
        "# --------------------------\n",
        "train_X, temp_X, train_y, temp_y = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "val_X, test_X, val_y, test_y = train_test_split(temp_X, temp_y, test_size=0.5, stratify=temp_y, random_state=42)\n",
        "\n",
        "# --------------------------\n",
        "# 4. Augmentation (stable)\n",
        "# --------------------------\n",
        "train_aug = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.3),\n",
        "    A.Rotate(limit=20, p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "])\n",
        "\n",
        "val_aug = A.Compose([])  # no augmentation\n",
        "\n",
        "def augment_images(X, y, aug):\n",
        "    X_aug, y_aug = [], []\n",
        "    for img, label in zip(X, y):\n",
        "        augmented = aug(image=(img*255).astype(np.uint8))['image']  # ensure uint8 for Albumentations\n",
        "        augmented = augmented / 255.0\n",
        "        X_aug.append(augmented)\n",
        "        y_aug.append(label)\n",
        "    return np.array(X_aug), np.array(y_aug)\n",
        "\n",
        "train_X_aug, train_y_aug = augment_images(train_X, train_y, train_aug)\n",
        "val_X_aug, val_y_aug = augment_images(val_X, val_y, val_aug)\n",
        "\n",
        "# --------------------------\n",
        "# 5. Build model\n",
        "# --------------------------\n",
        "base_model = Xception(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
        "base_model.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# --------------------------\n",
        "# 6. Initial training\n",
        "# --------------------------\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr  = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
        "\n",
        "history = model.fit(train_X_aug, train_y_aug,\n",
        "                    validation_data=(val_X_aug, val_y_aug),\n",
        "                    epochs=15,\n",
        "                    batch_size=8,\n",
        "                    callbacks=[early_stop, reduce_lr])\n",
        "\n",
        "# --------------------------\n",
        "# 7. Fine-tuning\n",
        "# --------------------------\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-50]:  # freeze first layers\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history_fine = model.fit(train_X_aug, train_y_aug,\n",
        "                         validation_data=(val_X_aug, val_y_aug),\n",
        "                         epochs=10,\n",
        "                         batch_size=8,\n",
        "                         callbacks=[early_stop, reduce_lr])\n",
        "\n",
        "# --------------------------\n",
        "# 8. Evaluate\n",
        "# --------------------------\n",
        "test_loss, test_acc = model.evaluate(test_X, test_y, batch_size=8)\n",
        "print(\"Test Accuracy (Experiment 5b, stable augmentation & fine-tuning):\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj8V5s8amDxJ",
        "outputId": "7edd87a7-7cbf-4e5c-e0b7-908636c764f1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 858ms/step - accuracy: 0.5035 - loss: 0.9185 - val_accuracy: 0.3846 - val_loss: 0.7608 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.5510 - loss: 1.1554 - val_accuracy: 0.3846 - val_loss: 0.7446 - learning_rate: 1.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.6055 - loss: 0.9058 - val_accuracy: 0.3846 - val_loss: 0.7290 - learning_rate: 1.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.6050 - loss: 0.8450 - val_accuracy: 0.4615 - val_loss: 0.7125 - learning_rate: 1.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.6162 - loss: 0.8074 - val_accuracy: 0.5000 - val_loss: 0.6933 - learning_rate: 1.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.6329 - loss: 0.6914 - val_accuracy: 0.5000 - val_loss: 0.6763 - learning_rate: 1.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.6669 - loss: 0.6005 - val_accuracy: 0.5000 - val_loss: 0.6569 - learning_rate: 1.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7401 - loss: 0.6263 - val_accuracy: 0.5000 - val_loss: 0.6339 - learning_rate: 1.0000e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.7477 - loss: 0.6190 - val_accuracy: 0.5385 - val_loss: 0.6131 - learning_rate: 1.0000e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.6681 - loss: 0.5542 - val_accuracy: 0.5769 - val_loss: 0.5879 - learning_rate: 1.0000e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.6655 - loss: 0.6336 - val_accuracy: 0.6154 - val_loss: 0.5658 - learning_rate: 1.0000e-04\n",
            "Epoch 12/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.7047 - loss: 0.5962 - val_accuracy: 0.6538 - val_loss: 0.5437 - learning_rate: 1.0000e-04\n",
            "Epoch 13/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.6669 - loss: 0.6757 - val_accuracy: 0.6538 - val_loss: 0.5194 - learning_rate: 1.0000e-04\n",
            "Epoch 14/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.6999 - loss: 0.5679 - val_accuracy: 0.6923 - val_loss: 0.4921 - learning_rate: 1.0000e-04\n",
            "Epoch 15/15\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8059 - loss: 0.4525 - val_accuracy: 0.8077 - val_loss: 0.4663 - learning_rate: 1.0000e-04\n",
            "Epoch 1/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.8132 - loss: 0.4857 - val_accuracy: 0.8077 - val_loss: 0.4008 - learning_rate: 1.0000e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.7952 - loss: 0.4348 - val_accuracy: 0.8846 - val_loss: 0.3295 - learning_rate: 1.0000e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8257 - loss: 0.3548 - val_accuracy: 0.8846 - val_loss: 0.2861 - learning_rate: 1.0000e-05\n",
            "Epoch 4/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9030 - loss: 0.2624 - val_accuracy: 0.9231 - val_loss: 0.2585 - learning_rate: 1.0000e-05\n",
            "Epoch 5/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9227 - loss: 0.1987 - val_accuracy: 0.9231 - val_loss: 0.2411 - learning_rate: 1.0000e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9274 - loss: 0.2189 - val_accuracy: 0.9231 - val_loss: 0.2011 - learning_rate: 1.0000e-05\n",
            "Epoch 7/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9324 - loss: 0.2219 - val_accuracy: 0.9615 - val_loss: 0.1713 - learning_rate: 1.0000e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9777 - loss: 0.1026 - val_accuracy: 0.9615 - val_loss: 0.1643 - learning_rate: 1.0000e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8558 - loss: 0.2677 - val_accuracy: 0.9615 - val_loss: 0.1493 - learning_rate: 1.0000e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9275 - loss: 0.1639 - val_accuracy: 0.9615 - val_loss: 0.1338 - learning_rate: 1.0000e-05\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9763 - loss: 0.2003\n",
            "Test Accuracy (Experiment 5b, stable augmentation & fine-tuning): 0.9615384340286255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# تحويل النتائج من tf.Tensor إلى numpy (إذا لزم الأمر)\n",
        "train_acc = np.array(history.history['accuracy'])\n",
        "val_acc   = np.array(history.history['val_accuracy'])\n",
        "train_loss = np.array(history.history['loss'])\n",
        "val_loss   = np.array(history.history['val_loss'])\n",
        "\n",
        "# إذا كنت تريد دمج Fine-tuning أيضًا\n",
        "train_acc_ft = np.array(history_fine.history['accuracy'])\n",
        "val_acc_ft   = np.array(history_fine.history['val_accuracy'])\n",
        "train_loss_ft = np.array(history_fine.history['loss'])\n",
        "val_loss_ft   = np.array(history_fine.history['val_loss'])\n",
        "\n",
        "# دمج الحلقات التدريبية\n",
        "acc_all = np.concatenate([train_acc, train_acc_ft])\n",
        "val_acc_all = np.concatenate([val_acc, val_acc_ft])\n",
        "loss_all = np.concatenate([train_loss, train_loss_ft])\n",
        "val_loss_all = np.concatenate([val_loss, val_loss_ft])\n",
        "\n",
        "epochs = range(1, len(acc_all)+1)\n",
        "\n",
        "# رسم دقة التدريب والتحقق\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, acc_all, 'b-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc_all, 'r-', label='Validation Accuracy')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# رسم خسارة التدريب والتحقق\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, loss_all, 'b-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss_all, 'r-', label='Validation Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "jemp1DaLnrI2",
        "outputId": "3812ce79-5919-4371-c5ef-835cc12c636c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import numpy as np\n",
        "\n",
        "# predictions\n",
        "y_pred_prob = model.predict(test_X)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)  # threshold 0.5\n",
        "\n",
        "# confusion matrix\n",
        "cm = confusion_matrix(test_y, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# عرض مصور\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Cancer', 'Aneurysm'])\n",
        "disp.plot(cmap='Blues')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "7HW0t-86sZmN",
        "outputId": "c5437734-49ba-4966-d091-9c79a838c43f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step\n",
            "Confusion Matrix:\n",
            " [[13  0]\n",
            " [ 1 12]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x78a41c997fe0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "H5_PATH = \"/content/ct_model.h5\"\n",
        "model.save(H5_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jB4je1qtDWi",
        "outputId": "d8f09250-24ae-4151-d37e-dbadfd1f7c3a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "loaded_model = load_model(H5_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgBP6PTNt-6o",
        "outputId": "a7d6738e-1dc1-4a4d-baeb-8a5e008a0b53"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = loaded_model.evaluate(test_X, test_y, batch_size=8)\n",
        "print(\"Loaded Model Test Accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ips-YUVuZfq",
        "outputId": "1424f194-56f4-46f7-ad73-6a3b8f674a83"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9763 - loss: 0.2003\n",
            "Loaded Model Test Accuracy: 0.9615384340286255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import os\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "def load_single_image(path):\n",
        "    if path.endswith('.jpg'):\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    else:  # dcm\n",
        "        dcm = pydicom.dcmread(path)\n",
        "        img = dcm.pixel_array.astype(np.float32)\n",
        "        img = np.clip(img, -100, 400)\n",
        "        img = (img - img.min()) / (img.max() - img.min()) * 255\n",
        "        img = img.astype(np.uint8)\n",
        "\n",
        "    img = cv2.resize(img, IMG_SIZE)\n",
        "    img = np.stack([img]*3, axis=-1)  # تحويل الرمادي إلى RGB\n",
        "    img = img / 255.0  # تطبيع\n",
        "    return np.expand_dims(img, axis=0)  # إضافة بعد batch\n"
      ],
      "metadata": {
        "id": "SVOhCfmxuhH1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/1_10.jpg\"  # ضع مسار الصورة هنا\n",
        "img = load_single_image(image_path)\n",
        "\n",
        "prediction = model.predict(img)[0][0]\n",
        "\n",
        "# التفسير\n",
        "if prediction >= 0.5:\n",
        "    print(f\"Prediction: Aneurysm ({prediction:.2f})\")\n",
        "else:\n",
        "    print(f\"Prediction: not Aneurysm ({prediction:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pIjSWV8u009",
        "outputId": "c4c6379a-77f8-4103-f2c6-7066da8de517"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step\n",
            "Prediction: Aneurysm (0.79)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "image_path = \"/content/1_11.jpg\"\n",
        "img = load_single_image(image_path)\n",
        "\n",
        "prediction = model.predict(img)[0][0]\n",
        "\n",
        "# التفسير\n",
        "if prediction >= 0.5:\n",
        "    print(f\"Prediction: Aneurysm ({prediction:.2f})\")\n",
        "else:\n",
        "    print(f\"Prediction: not Aneurysm ({prediction:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94UyHu-ZyduF",
        "outputId": "06411971-80fa-40a8-f34e-fcfc2ad14b1e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Prediction: not Aneurysm (0.04)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dCVZBo6003Tr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}